---
title: "Linear models"
author: "Alexandre Courtiol"
date: "`r Sys.Date()`"
output:
  ioslides_presentation:
    widescreen: true
    smaller: true
vignette: >
  %\VignetteIndexEntry{2 Linear models}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}

---
```{r setup, include=FALSE}
library(LM2GLMM)
```

## What is a linear model?

### What is a statistical model?

###***A statistical model represents, often in considerably idealized form, the data-generating process.*** [(wikipedia)](https://en.wikipedia.org/wiki/Statistical_model)
<br>

### What is linear?

###***The data-generating process is assumed to be a linear function: it is constructed from a set of terms by multiplying each term by a constant and adding the results .***

## Mathematical notation of LM: simple notation {.build}

<font size="5"> $y_i = \beta_0 + \beta_1 \times x_{1,i} + \beta_2 \times x_{2,i} + \dots + \beta_{p} \times x_{p,i} + \epsilon_i$ </font>
 
* $y_i$ = the observations to explain / explanatory variable / dependent variable
* $x_{j,i}$ = the predictors / explanatory variables / independent variables
* $\beta_j$ = the regression coefficients / model parameters
* $\beta_0$ = the intercept
* $\epsilon_i$ = the errors $\rightarrow$ **We assume: <font size="5"> $\epsilon_i \sim \mathcal{N}(0, \sigma^2)$</font>**

<font size="5"> $\hat{y_i} = \hat{\beta_0} + \hat{\beta_1} \times x_{1,i} + \hat{\beta_2} \times x_{2,i} + \dots + \hat{\beta_p} \times x_{p,i}$ </font>

* $\hat{y_i}$ = the predictions / predicted values
* $x_{j,i}$ = the predictors / explanatory variables / independent variables
* $\hat{\beta_j}$ = the (coefficient / parameter) estimates
* $y_i - \hat{y_i} = \varepsilon_i$ = the residuals

# Fitting linear models

## Fitting the model to the data...

### ... means estimating the values of the regression coefficients of the model.


## Fitting a model on simulated data

### Imagine an ideal (unrealistic) situation
We know that the process generating the height of aliens can be 
approximated by the following linear model:

* $\texttt{height}_i = 50 + 1.5 \times \texttt{humans_eaten}_{i} + \epsilon_i$
* $\epsilon_i \sim \mathcal{N}(0, \sigma^2 = 25)$

<br>

We can thus generate the data corresponding to 30 aliens that have eaten 
between 1 and 30 humans.

```{r alien data}
Alien <- data.frame(humans_eaten = 1:30)

set.seed(1L)
Alien$size <- rnorm(n = 30, mean = 50 + 1.5*Alien$humans_eaten, sd = sqrt(25))
```

## The Alien data

```{r alien data 2, eval = FALSE}
plot(size ~ humans_eaten, data = Alien, ylab = "Alien size (cm)", xlab = "No. of humans eaten")
abline(a = 50, b = 1.5, col = "green", lwd = 2)  ## True relationship
```

<div class="columns-2">

```{r alien data 2 eval, fig.align='center', fig.asp=1, fig.width=4, echo = FALSE}
plot(size ~ humans_eaten, data = Alien, ylab = "Alien size (cm)", xlab = "No. of humans eaten")
abline(a = 50, b = 1.5, col = "green", lwd = 2)
```

```{r alien data 3 eval, fig.align='center', fig.asp=1, fig.width=4, echo = FALSE}
plot(size ~ humans_eaten, data = Alien, ylab = "Alien size (cm)", xlab = "No. of humans eaten")
text(x = 15, y = 150, labels = "?", cex = 8, col = "green")
```
</div>


## How to fit a LM?

### By maximum likelihood
We want the $\hat{\beta_j}$ maximizing the likelihood.

The likelihood of the model (i.e. of a vector $\theta$ of the $\hat{\beta_j}$) given the data is 
equal to the probability density assumed for those data given those parameter
values, that is: $\displaystyle {\mathcal {L}}(\theta \mid x) = P(x \mid \theta)$.

<br>

### By ordinary least squares
We want the $\hat{\beta_j}$ minimizing the residual sum of squares (RSS).

The RSS = $\displaystyle\sum_{i=1}^{n}{\varepsilon_i^2}$.

### Both methods are equivalent in the case of LM!

## Fitting the Alien data using ```lm()``` as a blackbox

```{r fit alien lm}
mod_alien_lm <- lm(size ~ humans_eaten, data = Alien)
(coef_lm <- mod_alien_lm$coef) ## We expect something close to 50 and 1.5
(Alien$sigma2 <- summary(mod_alien_lm)$sigma^2)[1] ## We expect something close to 25
(logLik_lm <- logLik(mod_alien_lm)[[1]])
(rss_lm <- anova(mod_alien_lm)$"Sum Sq"[2])
```

## Recovering the min RSS from the fit

```{r rss alien}
(rss_lm <- anova(mod_alien_lm)$"Sum Sq"[2])

Alien$pred_lm <- coef_lm[1] + coef_lm[2] * Alien$humans_eaten
## Tip: this is the same as mod_alien_lm$fitted.values / fitted(mod_alien_lm) / predict(mod_alien_lm)

Alien$resid_lm <- Alien$size - Alien$pred_lm
## Tip: this is the same as mod_alien_lm$residuals / residuals(mod_alien_lm)

sum(Alien$resid_lm^2)
```


## The Residual Sum of Squares (RSS)

<div class="columns-2">
```{r alien RSS plot, fig.align='center', fig.asp=1, fig.width=5, echo = FALSE, fig.cap="Residuals"}
plot(size ~ humans_eaten, data = Alien, ylab = "Alien size (cm)", xlab = "No. of humans eaten", asp = 1)
points(pred_lm ~ humans_eaten, col = "blue", data = Alien, pch = 20)
with(Alien, segments(x0 = humans_eaten, x1 = humans_eaten, y0 = size, y1 = pred_lm, col = "orange"))
legend("topleft", bty = "n", col = c("black", "blue"), pch = c(1, 20), legend = c("obs", "pred"))
```

```{r alien RSS plot2, fig.align='center', fig.asp=1, fig.width=5, echo = FALSE, fig.cap="Squared residuals"}
plot(
  size ~ humans_eaten,
  data = Alien,
  ylab = "Alien size (cm)",
  xlab = "No. of humans eaten",
  asp = 1,
  col = NULL
  )
points(pred_lm ~ humans_eaten, col = "blue", data = Alien, pch = 20)
for (i in 1:nrow(Alien)) {
  with(Alien, polygon(
    x = c(
    humans_eaten[i],
    humans_eaten[i],
    humans_eaten[i] + abs(resid_lm[i]),
    humans_eaten[i] + abs(resid_lm[i])
    ),
    y = c(pred_lm[i], size[i], size[i], pred_lm[i])
    ))
}
with(Alien, segments(x0 = humans_eaten, x1 = humans_eaten, y0 = size, y1 = pred_lm, col = "orange"))
```
</div>

## Recovering the max (log-)likelihood from the fit

```{r alien loglik}
correction <- (nrow(Alien) - mod_alien_lm$rank) / nrow(Alien)
Alien$density <- dnorm(x = Alien$size, mean = Alien$pred_lm, sd = sqrt(Alien$sigma2*correction))
Alien[1, ]
```


<div class="columns-2">

```{r alien lik plot, fig.align='center', fig.asp=1, fig.width=4, echo = FALSE}
par(mar = c(4, 4, 1, 1))
curve(dnorm(x, mean = Alien[1, "pred_lm"], sd = sqrt(Alien[1, "sigma2"])), from = 30, to = 30 + Alien[1, "pred_lm"], ylab = "probability density", xlab = "size")
abline(h = 0, lty = 2)
abline(v = Alien[1, "pred_lm"], lty = 2, col = "blue")
points(x = Alien[1, "pred_lm"], y = 0, pch = 20, col = "blue")
points(x = Alien[1, "size"], y = 0)
segments(x0 = Alien[1, "pred_lm"], x1 = Alien[1, "size"], y0 = 0, y1 = 0, col = "orange")
segments(x0 = Alien[1, "size"], x1 = Alien[1, "size"], y0 = 0, y1 = Alien[1, "density"], col = "purple")
arrows(x0 = Alien[1, "size"], x1 = 30, y0 = Alien[1, "density"], y1 = Alien[1, "density"], col = "purple", length = 0.1)
```

```{r alien log density}
(logLik_lm <- logLik(mod_alien_lm)[[1]])
log(prod(Alien$density))
sum(log(Alien$density))
```

</div>

## Recovering ```sigma2``` from the fit

```{r alien sigma2}
summary(mod_alien_lm)$sigma^2
```

$\sigma^2 = \hat{\sigma^2} \times \frac{n - p}{n}$

```{r alien sigma2 cont}
correction <- (nrow(Alien) - 1) / (nrow(Alien) - mod_alien_lm$rank)
var(Alien$resid_lm) * correction
sum(Alien$resid_lm^2) / (nrow(Alien) - mod_alien_lm$rank)
```


## Recovering the estimates numerically

### By maximum likelihood
```{r def comput_logLik_Alien}
compute_logLik_Alien <- function(param, data = Alien) {
  predicts <- param["intercept"] + param["slope"] * data$humans_eaten
  sigma2 <- abs(param["sigma2"]) * ((nrow(data) - 2)/nrow(data))
  return(sum(dnorm(data$size, mean = predicts, sd = sqrt(sigma2), log = TRUE)))}

(theta.lm <- c("intercept" = coef_lm[1][[1]], "slope" = coef_lm[2][[1]],
               "sigma2" = summary(mod_alien_lm)$sigma[[1]]^2)) ## For testing

compute_logLik_Alien(param = theta.lm)
```

```{r def logLik Alien computation}
(optim(c("intercept" = 0, "slope" = 1, "sigma2" = 1), compute_logLik_Alien, control = list(fnscale = -1)))$par
```

## Recovering the estimates numerically

### By ordinary least squares

```{r def compute_rss_Alien}
compute_rss_Alien <- function(param, data = Alien) {
	predicts <- param["intercept"] + param["slope"] * data$humans_eaten
	return(sum((data$size - predicts)^2))
}

compute_rss_Alien(param = theta.lm)  ## For testing
```

```{r}
est_min_rss <- optim(c("intercept" = 0, "slope" = 1), compute_rss_Alien)
est_min_rss$par
est_min_rss$value / (nrow(Alien) - 2)
```

## Mathematical notation of LM: matrix notation
$$
\begin{bmatrix} y_1 \\ y_2 \\ y_3 \\ \dots \\ y_n \end{bmatrix} = 
\begin{bmatrix}
1 & x_{1,1} & x_{2,1} & \dots & & x_{p,1} \\
1 & x_{1,2} & x_{2,2} & \dots & & x_{p,2} \\
1 & x_{1,3} & x_{2,3} & \dots & & x_{p,3} \\
\dots \\
1 & x_{1,n} & x_{2,n} & \dots & & x_{p,n}
\end{bmatrix}
\begin{bmatrix}
\beta_0 \\ \beta_1 \\ \beta_2 \\ \beta_3 \\ \dots \\ \beta_n
\end{bmatrix} + 
\begin{bmatrix}
\epsilon_1 \\ \epsilon_2 \\ \epsilon_3 \\ \dots \\ \epsilon_n
\end{bmatrix}
$$

<br>

for short: <font size = 8> $Y = X \beta + \epsilon$ </font>; and again: <font size = 8> $\hat{Y} = X \hat{\beta}$ </font>

## Predictions using the matrix notation

```{r pred matrix}
X <- model.matrix(mod_alien_lm)
head(X)
```

```{r pred matrix 2}
X %*% coef(mod_alien_lm)
```

## Residuals using the matrix notation
```{r resid matrix}
Y <- as.matrix(Alien$size)
Y - X %*% coef(mod_alien_lm)
```

## Estimates using linear algebra

<font size = 8> $\hat{\beta} = (X^\text{T}X)^{-1}X^\text{T}Y$ </font> (see [wikipedia](https://en.wikipedia.org/wiki/Linear_least_squares_(mathematics)) for demonstration)

### The direct implementation works:
```{r lin algebra}
solve(t(X) %*% X) %*% t(X) %*% Y  ## Tip: solve(x) returns the inverse of the matrix x
```

... but ```lm()``` does not do that because it is somewhat inefficient.

For example, the computation ```t(X) %*% X``` does not consider that the same matrix is used twice, so it does not consider that this particular crossproduct leads to a symmetric matrix. Thus half of the computations could be spared.


## The QR decomposition

The goal is simply to decompose the model matrix into two new matrices that present nice properties for doing math efficiently.

```{r QR}
qr_list <- qr(X)  ## same as mod_alien_lm$qr
Q1 <- qr.Q(qr_list) ## dim = n * p
R <- qr.R(qr_list)  ## dim = p * p
head(Q1R <- Q1 %*% R, 3)
all.equal(X, Q1R, check.attributes = FALSE)  ## Q1R is equal to X!!
```

##

```{r cov matrix}
summary(mod_alien_lm)$sigma^2 * solve(t(X) %*% X)  ## same as vcov(mod_alien_lm)
```


# Junk for later

## A very simple example

```{r orange data}
OrangeTree1 <- subset(Orange, Tree == 1)
OrangeTree1
```


### Our first model
<font size="5"> $\texttt{circumference}_i = \beta_0 + \beta_{\texttt{age}} \times \texttt{age}_{i} + \epsilon_i$ </font>

```{r lm orange}
mod_orange_lm <- lm(circumference ~ age, data = OrangeTree1)
mod_orange_glm <- glm(circumference ~ age, data = OrangeTree1, family = gaussian())

```




## A very simple example




## A simple example

```{r UK data}
UKBoys <- subset(UK, sex == "Boy")
UKBoys$milk_f <- factor(UKBoys$milk)
mod_uk_boys <- lm(height ~ milk_f, data = UKBoys)
```



