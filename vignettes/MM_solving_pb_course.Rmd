---
title: "LMM: Solving LM problems"
author: "Alexandre Courtiol"
date: "`r Sys.Date()`"
output:
  ioslides_presentation:
    widescreen: true
    smaller: true
vignette: >
  %\VignetteIndexEntry{4.1 MM: Solving LM problems using LMM ------------------course}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
library(LM2GLMM)
library(spaMM)
library(lme4)
spaMM.options(nb_cores = 4L)
options(width = 120)
knitr::opts_chunk$set(cache = TRUE, cache.path = "./cache_knitr/MM_solving_pb/", fig.path = "./fig_knitr/MM_solving_pb/", fig.width = 5, fig.height = 5, fig.align = "center", error = FALSE)
```

<!-- cannot remove italic... :-( -->
```{css csssmall, echo=FALSE, chache=FALSE} 
.prettyprint.lang-small {
  background-color: transparent;
  line-height: 13px;
  font-size: 12px;
}
```

## Mixed-effects models

* 4.0 [Introduction to LMM & GLMM](./MM_intro_course.html)
* 4.1 [Solving LM problems using LMM](./MM_solving_pb_course.html)
* 4.2 [A showcase of some useful applications](./MM_showcase_course.html)

<br>

<div align="right">
[Back to main menu](./Title.html#2)
</div>


## You will learn in this session `r .emo("goal")`

* how to handle temporal and spatial autocorrelation
* how to model heteroskedasticity


# Temporal autocorrelation

## The ```AirPassengers``` data `r .emo("alien")`

```{r airpassenger data}
AirPassengers
```


## The ```AirPassengers``` data `r .emo("alien")`

```{r plot airpassenger data}
plot(AirPassengers)
```


## Reformating the dataset for the fit `r .emo("alien")`

```{r reshape airpassenger}
(air <- data.frame(passengers = as.numeric(AirPassengers),
                   year = rep(1949:1960, each = 12),
                   month = factor(rep(1:12, 12))))
```


## Looking at the average trend per year `r .emo("info")`

```{r airpassenger time trend per year}
plot(with(air, tapply(passengers, year, mean)) ~ I(1949:1960),
     ylab = "Mean number of passengers", xlab = "Year", type = "b")
```


## Looking at the average trend per month `r .emo("info")`

```{r airpassenger time trend per month}
plot(with(air, tapply(passengers, month, mean)) ~ I(1:12),
     ylab = "Mean number of passengers", xlab = "Month", type = "h")
```


## Simple LM fit `r .emo("info")`

```{r airpassenger simple fit, class.output="small"}
(fit_air_LM <- lm(passengers ~ year + month, data = air))
```


## The problem `r .emo("info")`
```{r airpassenger assumptions}
par(mfrow = c(2, 2))
plot(fit_air_LM)
```


## The problem `r .emo("info")`

```{r airpassenger residuals}
plot(residuals(fit_air_LM), type = "b")
abline(h = 0, lty = 2, col = "red")
```


## The problem `r .emo("info")`

```{r airpassenger dw test}
lmtest::dwtest(fit_air_LM)
```

<br>

There is strong serial autocorrelation in these data!


## The problem `r .emo("info")`

```{r airpassenger acf}
acf(residuals(fit_air_LM))
```


## Autoregressive fit using **{spaMM}** `r .emo("practice")`

```{r spaMM air, message = FALSE, class.output="small"}
air$time <- 1:nrow(air)
library(spaMM)
(fit_air_spaMM <- fitme(passengers ~ month + year + AR1(1|time), data = air))
```


## Autoregressive fit using **{glmmTMB}** `r .emo("practice")`

```{r glmmTMB air, message = FALSE, class.output="small"}
library(glmmTMB)
air$group <- factor("A")
air$Year <- air$year - 1949 ## remove 1949 to help with convergence
air$Time <- numFactor(air$time)
(fit_air_glmmTMB <- glmmTMB(passengers ~ month + Year + ar1(Time + 0|group), data = air))
```


## Autocorrelation estimate `r .emo("practice")`

You can extract the autocorrelation estimate:
```{r corr values}
spaMM::get_ranPars(fit_air_spaMM, which = "corrPars")[[1]][[1]]
get_cor(getME(fit_air_glmmTMB, "theta")[2])
```

## Assumptions `r .emo("info")`

Unfortunately, in the presence of correlation function(s) in the models, the approach followed by **{DHARMa}** is no longer valid and there is no easy workaround I am aware of...

```{r resid, fig.width = 9, fig.height = 4}
plot(simulateResiduals(fit_air_spaMM))
```

## Assumptions `r .emo("info")`

Unfortunately, in the presence of correlation function(s) in the models, the approach followed by **{DHARMa}** is no longer valid and there is no easy workaround I am aware of...

... but you can still check which model fits the data the best:
```{r AIC}
AIC(fit_air_LM)
```
```{r AIC2}
AIC(fit_air_spaMM)
```
```{r AIC3, echo=FALSE}
print(AIC(fit_air_spaMM))
```

Note: 

- you need to compare here the AIC from the LM to the marginal AIC from the LMM.

## Fitted values `r .emo("info")`

```{r air fitted, fig.height = 4, fig.width = 4}
pred_spaMM <- predict(fit_air_spaMM)
plot(passengers ~ time, data = air, type = "l", lwd = 3, ylim = c(0, 700), ylab = "Passengers")
points(pred_spaMM ~ air$time, type = "l", col = "green")
```

Note: never extrapolate using such model! Obtaining a perfect fit is not unusual in the presence of autocorrelation.


## Testing the effect of years `r .emo("practice")`

```{r spaMM air 2}
fit_air_spaMM_no_year <- fitme(passengers ~ month + AR1(1|time), data = air)
anova(fit_air_spaMM, fit_air_spaMM_no_year)
```

```{r TMB air 2}
fit_air_TMB_no_year <- glmmTMB(passengers ~ month + ar1(Time + 0|group), data = air)
anova(fit_air_glmmTMB, fit_air_TMB_no_year)
```


<!--
# Temporal autocorrelation in continuous time

## The `bodyweight` dataset

```{r bodyweight data, fig.width = 10}
plot(bodyweight)
```


## Fitting with the exponential correlation function

```{r bodyweight fitme spaMM}
(fit_rat1 <- fitme(weight ~ Diet * Time + (Time|Rat) + Matern(1|Time),
                         fixed = list(nu = 0.5),
                         data = bodyweight, method = "REML"))
```


## Fitting with the ```Matern()``` correlation function

```{r bodyweight fitme spaMM 2}
(fit_rat2 <- fitme(weight ~ Diet * Time + (Time|Rat) + Matern(1|Time),
                         data = bodyweight, method = "REML"))
```


## Plotting the autocorrelation functions
```{r plot autocorr Matern prep}
time_for_pred <- seq(0, 30, length.out = 100)
pred_corr1 <- MaternCorr(time_for_pred,
                         rho = fit_rat1$corrPars[[1]]$rho,
                         nu = fit_rat1$corrPars[[1]]$nu)
pred_corr2 <- MaternCorr(time_for_pred,
                         rho = fit_rat2$corrPars[[1]]$rho,
                         nu = fit_rat2$corrPars[[1]]$nu)
```

## Plotting the autocorrelation functions
```{r plot autocorr Matern, fig.width=3.5, fig.height=3.5}
plot(pred_corr1 ~ time_for_pred, type = "l", lwd = 2, col = "red", ylim = c(0, 1), xlab="Time", ylab="Correlation")
points(pred_corr2 ~ time_for_pred, type = "l", lwd = 2, col = "purple", ylim = c(0, 1))
```
Note: this is not OK, the full Matern model badly converged...


## Model comparison
```{r Matern vs AR1}
print(AIC(fit_rat1))
print(AIC(fit_rat2))
```

<br>

Note: the model should not look really different in their ability to fit the data (but there is currently a problem with **{spaMM}** here... I will fix it ASAP).


## AR1

```{r bodyweight fitme AR1 spaMM}
(fit_rat_AR1 <- fitme(weight ~ Diet * Time + (Time|Rat) + AR1(1|Time),
                            data = bodyweight, method = "REML"))
```


## AR1 vs Matern
```{r plot autocorr Matern 2}
pred_corr3 <- fit_rat_AR1$corrPars[[1]]$ARphi^time_for_pred
plot(pred_corr1 ~ time_for_pred, type = "l", lwd = 5, col = "red", ylim = c(0, 1), xlab="Time", ylab="Correlation")
points(pred_corr3 ~ time_for_pred, type = "l", lwd = 2, col = "green", ylim = c(0, 1))
```


## AR1 vs Matern

```{r AR1 vs Matern}
logLik(fit_rat1)[[1]] ## Matern nu = 0.5
logLik(fit_rat_AR1)[[1]] ## AR1
round(fixef(fit_rat1) - fixef(fit_rat_AR1), 3)
```

<br>

Note 1: AR1 and Matern (with nu = 0.5) are equivalent (if time is discrete)!

Note 2: AR1 cannot work if time is not discrete.


## Model comparison

```{r corrHLfit spaMM2}
fit_rat_noAR <- fitme(weight ~ Diet * Time + (Time|Rat), data = bodyweight,
                            method = "REML")
```

```{r corrHLfit spaMM2 2}
print(AIC(fit_rat1))
print(AIC(fit_rat_noAR))
```

<br>

Note: the model accounting for the autocorrelation fits the data best!


## Testing the overall effect of diet

### ```spaMM```

```{r spaMM rat}
fit_rat3ML <- fitme(weight ~ Diet * Time + (Time|Rat) + AR1(1|Time),
                          data = bodyweight, method = "ML")
fit_rat_no_diet <- fitme(weight ~ 1 + Time + (Time|Rat) + AR1(1|Time),
                          data = bodyweight, method = "ML")
anova(fit_rat3ML, fit_rat_no_diet)
```

-->

<!--
## More complex autocorrelation functions

There are more complex autocorrelation functions out there.

**{spaMM}**:
```{r spaMM full Matern}
(fit_rat_Matern_nugget <- fitme(weight ~ Diet * Time + (Time|Rat) + Matern(1|Time), data = bodyweight,
                                init = list(Nugget = 0.1)))  ## here estimated at zero but does not have to be!
```
-->

## More complex autocorrelation functions `r .emo("info")`

There are more complex autocorrelation functions out there.

The package **{nlme}** used to be the only option out there, but this package is problematic in many ways.

Instead, I would now dig further into **{glmmTMB}** and **{spaMM}** which allows for already quite a lot of possibilities and more autocorrelation will probably be added as these packages develop.

<!--
**{nlme}**:
```{r other correlations}
library(nlme)
fit_rat1 <- lme(weight ~ Diet * Time, random = ~ Time|Rat, data = bodyweight) 
fit_rat_AR1 <- update(fit_rat1, corr = corAR1(form = ~ Time))
fit_rat_corExp <- update(fit_rat1, corr = corExp(form = ~ Time, nugget = FALSE))
fit_rat_corExp_Nugget <- update(fit_rat1, corr = corExp(form = ~ Time, nugget = TRUE))
fit_rat_corRatio <- update(fit_rat1, corr = corRatio(form = ~ Time))
fit_rat_corSpher <- update(fit_rat1, corr = corSpher(form = ~ Time))
fit_rat_corLin <- update(fit_rat1, corr = corLin(form = ~ Time))
fit_rat_corGaus <- update(fit_rat1, corr = corGaus(form = ~ Time))
c(AIC(fit_rat1)[[1]], AIC(fit_rat_AR1)[[1]], AIC(fit_rat_corExp)[[1]],  AIC(fit_rat_corExp_Nugget)[[1]],
  AIC(fit_rat_corRatio)[[1]], AIC(fit_rat_corSpher)[[1]], AIC(fit_rat_corLin)[[1]], AIC(fit_rat_corGaus)[[1]])
```

<br>

Note: do not compare AIC between ```spaMM``` and ```nlme```, as the latter seems not to account for a fixed term in the computation of the likelihood!
-->

# Spatial autocorrelation

## Maximum normalised-difference vegetation index in north Cameroon `r .emo("alien")`

```{r loaloa data}
data("Loaloa")
ndvi <- Loaloa[, c("maxNDVI", "latitude", "longitude")]
head(ndvi)
```


## Visualising the data `r .emo("practice")`

```{r loaloa plot, fig.width = 9}
library(maps)
spaMMplot2D(x = ndvi$longitude, y = ndvi$latitude, z = ndvi$maxNDVI, add.map = TRUE,
            xlab = "Longitude", ylab = "Latitude", plot.title = title(main = "max NDVI"))
```


## Visualising the data `r .emo("practice")`

```{r loaloa pairs}
pairs(ndvi)
```


## Fitting the model `r .emo("practice")`

```{r mod ndvi}
(fit_ndvi1 <- fitme(maxNDVI ~ 1 + Matern(1|longitude + latitude), data = ndvi, method = "REML"))
```


## Fitted values `r .emo("practice")`

```{r mapMM 1, fig.width = 9}
mapMM(fit_ndvi1, add.map = TRUE, plot.title = title(xlab = "Longitude", ylab = "Latitude"))
```


## Predictions `r .emo("practice")`

```{r mapMM 2, fig.width = 9}
filled.mapMM(fit_ndvi1, add.map = TRUE, plot.title = title(xlab = "Longitude", ylab = "Latitude"))
```


## Prediction uncertainty `r .emo("practice")`

It is also possible to estimate how the uncertainty of the predictions varies in space:

```{r loaloa pred uncertainty}
x.for.pred <- seq(min(ndvi$longitude), max(ndvi$longitude), length.out = 100)
y.for.pred <- seq(min(ndvi$latitude), max(ndvi$latitude), length.out = 50)
data.for.pred <- expand.grid(longitude = x.for.pred, latitude = y.for.pred)
data.for.pred$predVar <- get_predVar(fit_ndvi1, newdata = data.for.pred)
m <- matrix(data.for.pred$predVar, ncol = length(y.for.pred))
```


## Prediction uncertainty `r .emo("practice")`

```{r loaloa plot uncertainty, fig.width = 8}
spaMM.filled.contour(x = x.for.pred, y = y.for.pred, z = m, plot.axes = {
  points(ndvi[, c("longitude", "latitude")]); axis(1); axis(2)}, col = spaMM.colors(redshift = 3),
  plot.title = title(xlab = "Longitude", ylab = "Latitude"))
```


## Spatial fit in **{glmmTMB}** `r .emo("practice")`

You can also use **{glmmTMB}**, but it is considerable slower than **{spaMM}** with a Matern correlation function, and it does not seem quite ready yet (status = "experimental/untested").

Here is what seems to be the correct syntax (not yet properly documented):
```{r mod ndvi TMB, warning=FALSE}
ndvi$group <- factor("A")
ndvi$coord <- numFactor(ndvi$latitude, ndvi$longitude)
fit_ndvi1_TMB <- glmmTMB(maxNDVI ~ 1 + mat(0 + coord|group), data = ndvi, REML = TRUE)
```

Note:

- see `vignette("covstruct", package = "glmmTMB")` for more details.


# Heteroscedasticity

## Heteroscedasticity `r .emo("info")`

We used random effects to model variance components from random variables.

We can thus use the same kind of tools to also model the variance components of the errors.

Do not mix-up random variance components from residual ones: remember that in the error, all covariance terms are null (by definition).

## The `bodyweight` dataset `r .emo("alien")`

```{r bodyweight data2, fig.width = 10}
head(bodyweight)
str(bodyweight)
```

## The `bodyweight` dataset `r .emo("alien")`

```{r bodyweight data3, fig.width = 10}
coplot(weight ~ Time | Rat * Diet, data = bodyweight, panel = panel.smooth)
```

## Let's model growth in rats `r .emo("practice")`

```{r rat hetero}
(fit_rat <- fitme(weight ~ Diet * Time + (Time|Rat) + AR1(1|Time), data = bodyweight,
                  method = "REML"))
```


## Let's model growth in rats `r .emo("practice")`

```{r rat hetero plot}
coplot(residuals(fit_rat) ~ I(1:nrow(bodyweight)) | bodyweight$Diet, show.given = FALSE)
```


## Let's model growth in rats `r .emo("practice")`

```{r rat hetero 2, class.output="small"}
(fit_rat_hetero <- fitme(weight ~ Diet * Time + (Time|Rat) + AR1(1|Time), data = bodyweight,
                         method = "REML", resid.model = ~ Diet))
```


## Let's test the overal effect of the diet `r .emo("practice")`

```{r hetero 3, results='hold'}
fit_rat_hetero <- fitme(weight ~ Diet * Time + (Time|Rat) + AR1(1|Time), data = bodyweight,
                        method = "ML", resid.model = ~ Diet)

fit_rat_hetero0 <- fitme(weight ~ Time + (Time|Rat) + AR1(1|Time), data = bodyweight,
                         method = "ML", resid.model = ~ Diet)

anova(fit_rat_hetero, fit_rat_hetero0) ## parametric bootstrap would be best here, but very slow
                                       ## and it would not affect the conclusion since the effect is very strong
```


## Heteroscedasticity in LM `r .emo("practice")`

You can also model heteroskedasticity in LM as we just saw it:

```{r hetero simple}
set.seed(1L)
d <- data.frame(y = c(rnorm(100, mean = 10, sd = sqrt(10)),
                      rnorm(100, mean = 20, sd = sqrt(20))),
                group = factor(c(rep("A", 100), rep("B", 100))))

fit_hetero_spaMM <- fitme(y ~ group, resid.model = ~ group, data = d, method = "REML")
phi_spaMM <- summary(fit_hetero_spaMM, verbose = FALSE)$phi[, "Estimate"] ## in log scale using contrast treatment
exp(c(phi_spaMM[[1]], sum(phi_spaMM))) ## residual variance in response scale without contrasts
```

Once again **{glmmTMB}** does that too:
```{r hetero simple glmmTMB}
fit_hetero_glmmTMB <- glmmTMB(y ~ group, dispformula = ~ group, data = d, REML = TRUE)
phi_glmmTMB <- fit_hetero_glmmTMB$fit$par ## in log scale using contrast treatment
exp(c(phi_glmmTMB[[1]], sum(phi_glmmTMB))) ## residual variance in response scale without contrasts
```
Note: **{spaMM}** even allows for including random effects influencing the residual variance! `r .emo("slow")``r .emo("slow")``r .emo("slow")`


## What you need to remember `r .emo("goal")`

* how to handle temporal and spatial autocorrelation
* how to model heteroskedasticity


# Table of contents

## Mixed-effects models

* 4.0 [Introduction to LMM & GLMM](./MM_intro_course.html)
* 4.1 [Solving LM problems using LMM](./MM_solving_pb_course.html)
* 4.2 [A showcase of some useful applications](./MM_showcase_course.html)

<br>

<div align="right">
[Back to main menu](./Title.html#2)
</div>
