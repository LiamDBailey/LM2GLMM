---
title: "LM: Uncertainty in point estimates"
author: "Alexandre Courtiol"
date: "`r Sys.Date()`"
output:
  ioslides_presentation:
    widescreen: true
    smaller: true
vignette: >
  %\VignetteIndexEntry{2.2 Uncertainty in point estimates}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
library(LM2GLMM)
library(spaMM)
library(lattice)
library(mvtnorm)
library(rgl)
spaMM.options(nb_cores = 4L)
knitr::knit_hooks$set(webgl = hook_webgl) ## for rgl
knitr::opts_chunk$set(cache = TRUE, cache.path = "./cache_knitr/LM_uncertainty/", fig.path = "./fig_knitr/LM_uncertainty/", error = TRUE)
```

## The Linear Model: LM

* 2.0 [Introduction](./LM_intro.html)
* 2.1 [Fitting procedure](./LM_fitting.html)
* 2.2 [Uncertainty in point estimates](./LM_uncertainty.html)
* 2.3 [Tests](./LM_tests.html)
* 2.4 [Assumptions and Outliers](./LM_assumptions.html)
* 2.5 [Let's practice more](./LM_practice.html)

<br>

<div align="right">
[Back to main menu](./Title.html#2)
</div>


## You will learn in this session

* what point estimates are
* that point estimates are random variables
* that estimates are not necessarily independent from each other
* what 95% Confidence Intervals are
* that there are 3 main ways to compute 95% CI
* what the parametric bootstrap is
* what likelihood profiling is
* what statistical coverage is
* what 95% CI on the mean response are
* what 95% Prediction Intervals are


# Introduction

## Summary of point estimates

Fitting a model leads point estimates:
```{r point estimates}
set.seed(123L)
Alien <- simulate_Aliens()
fit_stats <- lm(size ~ humans_eaten, data = Alien)
sigma2_error <- summary(fit_stats)$sigma^2
c(coef(fit_stats), sigma2 = sigma2_error)

fit_spaMM_ML   <- fitme(size ~ humans_eaten, data = Alien, method = "ML")
fit_spaMM_REML <- fitme(size ~ humans_eaten, data = Alien, method = "REML")
c(fit_spaMM_ML$fixef, sigma2 = fit_spaMM_REML$phi)  ## in LM fixef are same for ML and REML but not in LMM
```
Point estimates are random variable. Thus, their distributions must be characterised to derive tests and intervals. 


# Theoretical distributions of point estimates

## Covariances of the $\widehat{\beta}$s

You can easily recover the covariance matrix of the regression estimates from the fitted models:
<!--
```{r vcov}
XTX <- crossprod(model.matrix(fit_stats))
## XTX/sigma2_error is the Hessian (matrix of second derivative) of Lik(X)
## the inverse of the Hessian gives the covariance matrix
sigma2_error * solve(XTX)
```
-->

```{r vcov2}
vcov(fit_stats)
vcov(fit_spaMM_REML)  ## don't use the ML fit here!
```

## The $\widehat{\beta}$s are asymptotically normaly distributed

We create a set of candidate values for our 2 regression parameters:

```{r compute density betas}
candidate_intercept_u <- seq(from = 30, to = 70,  by = 0.1)
candidate_slope_u     <- seq(from =  0, to = 2.5, by = 0.1)
```

We extract the densities at each point given the model parameter estimates:

```{r compute density betas2}
candidates <- expand.grid(candidate_intercept = candidate_intercept_u, candidate_slope = candidate_slope_u)
candidates$d <- dmvnorm(x = candidates[, 1:2], mean = coef(fit_stats), sigma = vcov(fit_stats), log = FALSE)
head(candidates)
```

<br>

Note: we will reuse the candidate values repeatedly.

## Multivariate density of the estimates for $\widehat{\beta}$s

```{r plot rgl, webgl=TRUE, fig.align="center"}
library(rgl)  ## to make interactive plots!
with(data = candidates, plot3d(candidate_intercept, candidate_slope, d))
```


## Same plot with ```graphics```

```{r plot graphics, fig.align = "center", fig.height = 4, fig.width = 4}
contour(x = candidate_intercept_u, y = candidate_slope_u,
        z = matrix(candidates$d, nrow = length(candidate_intercept_u)),
        nlevels = 5, xlab = "intercept", ylab = "slope")
```


## $\widehat{\sigma}^2$ is asymptotically Gamma distributed 

$\widehat{\sigma}^2$ follows a $\Gamma$ distribution with mean  = $\texttt{error variance}$ and var = $2 ( \texttt{error variance})^2 / (n-p)$.

[for $\Gamma$, mean = $\texttt{shape} \times \texttt{scale}$ and var = 
$\texttt{shape} \times \texttt{scale}^2$]

```{r gamma, fig.align = "center", fig.height = 4, fig.width = 4}
curve(dgamma(x, shape = fit_stats$df.residual/2, scale = 2*sigma2_error/fit_stats$df.residual),
    from = 0, to = 100, xlab = "sigma2_error", ylab = "probability density", lwd = 3)
```


# Empirical distributions of point estimates

## How to know what the distributions of point estimates really are?

In general you cannot, but in the specific case of Aliens we can retrieve it because we know from Goddess Emerald Lion what the true data-generating process is.

The idea is very simple: we are going to generate many samples from the population using our simulation function, fit one model on each sample, and extract the points estimates for each fit.

As you will see, the empirical distributions are quite far from the theoretical ones. This is because our sample size is quite small.


## Empirical distribution of $\widehat{\beta}$s

```{r redraw samples}
set.seed(123)
new_beta_estimates <- t(replicate(1000, coef(update(fit_stats, data = simulate_Aliens()))))
```

<div class="columns-2">

```{r plot ecdf intercept, fig.align = "center", fig.height = 3.5, fig.width = 3.5}
curve(pnorm(x, mean = coef(fit_stats)[1],
    sd = sqrt(vcov(fit_stats)[[1]])),
    from = 30, to = 70, ylab = "cdf", lwd = 3)
plot(ecdf(new_beta_estimates[, 1]), col = "red",
     add = TRUE)
```

```{r plot ecdf slope, fig.align = "center", fig.height = 3.5, fig.width = 3.5}
curve(pnorm(x, mean = coef(fit_stats)[2],
    sd = sqrt(vcov(fit_stats)[[4]])),
    from = 0, to = 2.5, ylab = "cdf", lwd = 3)
plot(ecdf(new_beta_estimates[, 2]), col = "red",
     add = TRUE)
```

</div>


## Empirical distribution of $\widehat{\sigma}^2$

```{r plot ecdf sigma2, fig.align = "center", fig.height = 4, fig.width = 4}
new_sigma2_error <- t(replicate(1000, summary(update(fit_stats, data = simulate_Aliens()))$sigma^2))
curve(pgamma(x, shape = fit_stats$df.residual/2, scale = 2*summary(fit_stats)$sigma^2/fit_stats$df.residual),
      from = 0, to =100, ylab = "cdf", lwd = 3)
plot(ecdf(new_sigma2_error), col = "red", add = TRUE)
```

# Confidence intervals

## What is a confidence interval?

### Definitions

For any interval-construction method applied to samples from a distribution characterized by some parameter value $k$, the **coverage** is the probability that the interval contains $k$.

An interval is an (exact) **confidence interval** with given coverage `X` if its coverage is `X` for any parameter value $k$.

Note: most methods for building interval computation are approximate, i.e. the empirical coverage differs from the given coverage `X`.

### Interpretation

Since the observed data correspond to a randomly selected set, then it is likely that the true value of the parameter lies within the confidence interval. Yet, you never know for sure (when using real data).

### Example

If you fit 100 models and compute for each one 95% confidence interval for a given point estimate, you expect that 95 should include the real (unknown) value that the parameter has in the true data generating process. 


# Confidence intervals: asymptotic

## CI for $\widehat{\beta}$s with known variance {.build}

<font size = 5> $\widehat{\beta}\sim \mathcal{N}(\beta, \sigma_{\widehat{\beta}})$ </font>

<font size = 5> $z = \frac{\widehat{\beta} - \beta}{\sigma_{\widehat{\beta}}}\sim \mathcal{N}(0, 1)$ </font>

<font size = 5> 95% CI for $z = [\mathrm{Q}0.025_{\mathcal{N}}; \ \mathrm{Q}0.975_{\mathcal{N}} ]$ </font>

```{r quantile norm}
c(Q0.025_N = qnorm(0.025), Q0.975_N = qnorm(0.975))
```

<font size = 5> 95% CI for $\widehat{\beta} = [\widehat{\beta} + \mathrm{Q0.025}_{\mathcal{N}} \times \sigma_{\widehat{\beta}}; \ \widehat{\beta} + \mathrm{Q0.975}_{\mathcal{N}} \times \sigma_{\widehat{\beta}}]$ </font>


## CI for $\widehat{\beta}$s with estimated variance {.build}

<font size = 5> $\widehat{\beta}\sim \mathcal{N}(\beta, \sigma_{\widehat{\beta}})$ </font>

<font size = 5> $t = \frac{\widehat{\beta} - \beta}{\widehat{\sigma_{\widehat{\beta}}}}\sim \mathcal{t}_{n - p}$ </font> ($t$ = Student's t distribution)

<font size = 5> 95% CI for $t = [\mathrm{Q}0.025_{\mathcal{t}_{n - p}}; \ \mathrm{Q}0.975_{\mathcal{t}_{n - p}}]$ </font>

```{r quantile t}
c(Qt_0.025 = qt(0.025, df = 10), Qt_0.975 = qt(0.975, df = 10))  ## with n-p = 10 (also try with 1000)
```

<font size = 5> 95% CI for $\widehat{\beta} = [\widehat{\beta} + \mathrm{Q}0.025_{\mathcal{t}_{n - p}} \times \widehat{\sigma_{\widehat{\beta}}}; \ \widehat{\beta} + \mathrm{Q}0.975_{\mathcal{t}_{n - p}} \times \widehat{\sigma_{\widehat{\beta}}}]$ </font>


## Computing 95% CI asymptotically: an example

Many fitting methods have methods defined for that:
```{r CI Wald}
confint(fit_stats)
```

And if not, it is easy to compute by hand:
```{r CI Wald hand}
quantile_min <- qt(0.025, fit_stats$df.residual)
quantile_max <- qt(0.975, fit_stats$df.residual)
cbind(coef(fit_stats) + quantile_min * sqrt(diag(vcov(fit_stats))),
      coef(fit_stats) + quantile_max * sqrt(diag(vcov(fit_stats))))
```


## Coverage of asymptotic 95% CI

```{r coverage CI Wald}
set.seed(1L)
mean(replicate(1000, sum(findInterval(confint(update(fit_stats, data = simulate_Aliens()))[1, ], 50)) == 1))
mean(replicate(1000, sum(findInterval(confint(update(fit_stats, data = simulate_Aliens()))[2, ], 1.5)) == 1))
```

<br>

The coverage of the CI based on the Student distribution is great (asymptotically this method is perfect for LM).

Since it is however not the case for more complex models, we will see now introduce other methods which will be easier to understand in the current context (simple LM) than when we will really need them.


# Confidence intervals: parametric bootstrap

## The general idea of bootstraping methods

The aim of the boostrap is to approximate the distribution of a statistic, in cases where parameters are not known (as usual) and where this distribution is not known analytically.

* When we simulate, we decide what the parameter values really are.
* When we fit, we estimate what the unknown parameter values are.
* Bootstrap: something in the middle; we simulate new observations considering the estimates as the true parameter values.

<!--
    * Non-parametric bootstrap: bootstrap samples that are iid (independent and identically distributed) from the point of view of the empirical distribution.
    * Parametric bootstrap: bootstrap samples that are iid from the point of view of the estimates.
* For linear models there are reason to expect parametric bootstrap to work.
-->

## The idea of the parametric bootstrap

We have:

* one real parameter (out of one possible): $a$
* one estimate (out of many possible): $\widehat{a}$
* bootstrap: a set of $a^*$

<br>
 
We assume that:

* the difference $\widehat{a} - a$ follows the same distribution than the difference $a^* - \widehat{a}$

<!--
Thus

$\widehat{a} - a \sim \widehat{a} - (a^* - \widehat{a}) = 2\widehat{a} - a^*$

Example using the bootstrap expectation:

If $a = 1$ and $\widehat{a} = 2$ then we expect $\overline{a^*} = 3$;

Reciprocally,

if $\overline{a^*} = 3$ and $\widehat{a} = 2$, we infer $\widehat{a} - a \sim 2\widehat{a} - \overline{a^*} = 2 \times 2 - 3 = 1$ so $a \sim \widehat{a} - 1 = 1$.
-->

<!--
## Computing 95% CI for estimates by parametric bootstrap

```{r CI confint for comp}
confint(fit_stats)  ## not a bootstrap, asymptotic (for comparison)
```

We no longer use the knowledge of the asymptotic distribution:

```{r CI param boot}
res_sim <- do.call("rbind", sapply(1:100, function(i) {
    newYs <- simulate(fit_stats)
    t(coef(lm(as.matrix(newYs) ~ humans_eaten, data = Alien)))
    }, simplify = FALSE))
(confint_boot <- rbind(quantile(2*coef(fit_stats)[1] - res_sim[, 1], probs = c(0.025, 0.975)),
                       quantile(2*coef(fit_stats)[2] - res_sim[, 2], probs = c(0.025, 0.975))))
```
-->

## Computing 95% CI by parametric bootstrap

```{r CI param boot 2}
CI_boot <- function(fit, param, nboot) {
  newYs <- simulate(fit, nsim = nboot) ## simulate new responses!!
  res_sim <- sapply(1:nboot, function(i) {
    newdata <- model.frame(fit) ## extract the data
    newdata[, 1] <- newYs[, i] ## replace the response var
    newfit <- update(fit, data = newdata)
    coef(newfit)[[param]]
  })
  boot::boot.ci(boot.out = list(R = length(res_sim)),
                t0 = coef(fit)[[param]],
                t  = res_sim,
                type = "basic")$basic[, 4:5]
} ## to use with spaMM fit, just run coef.HLfit <- fixef.HLfit beforehand
```

```{r CI param boot 3}
CI_boot(fit = fit_stats, param = "(Intercept)", nboot = 100)
CI_boot(fit = fit_stats, param = "humans_eaten", nboot = 100)
```


<!--
## Testing the coverage of the 95% CI (using boot)

```{r coverage CI param boot proper 3,eval = FALSE}
CIboot2c <- function(rep = 100, i){
  data <- simulate_Aliens()
  mod <- update(fit_stats, data = data)
  newYs <- simulate(mod, nsim = rep)
  res_sim <- t(coef(lm(as.matrix(newYs) ~ humans_eaten, data = data)))
  boot.ci(boot.out = list(R = nrow(res_sim)),
          t0 = coef(mod)[[i]],
          t  = res_sim[, i, drop = FALSE],
          var.t0 = vcov(mod)[i, i],
          var.t = rep(var(res_sim[, i]), nrow(res_sim)),
          type = "stud")$student[, 4:5]
}
set.seed(1L)
c(mean(replicate(5000, sum(findInterval(CIboot2c(i = 1), 50)) == 1)),
  mean(replicate(5000, sum(findInterval(CIboot2c(i = 2), 1.5)) == 1)))
```

<br>

Note: here it accounts for the uncertainty in the estimation of the variance (but not great either...).
-->


# Confidence intervals: likelihood profiling

## Computing the likelihood for specific parameters

```{r logLik fixed}
logLik(lm(size ~ 0 + offset(50 + 1.5 * humans_eaten), data = Alien))

logLik(fitme(size ~ 0 + offset(50 + 1.5 * humans_eaten), fixed = list(phi = 25), data = Alien))
```

<br>

Note: ```spaMM``` allows the fixation of the variance in addition to the fixation of the other parameters.


## Likelihood profiling 1 parameter: $\widehat{\sigma}^2$

```{r profile sigma2, fig.align = "center", fig.width = 4, fig.height = 4}
fit_spaMM_allfix <- fitme(size ~ humans_eaten, fixed = list(phi = 25), data = Alien, method = "REML")
candidate_sigma2 <- seq(10, 100, 0.5)
logLik_profile <- sapply(candidate_sigma2, function(sigma2) ## for each sigma2 we re-estimate other parameters
  logLik(update(fit_spaMM_allfix, fixed = list(phi = sigma2))))
plot(logLik_profile ~ candidate_sigma2, type = "l")
abline(v = 25, col = "green", lwd = 2)
abline(v = fit_spaMM_REML$phi, col = "blue", lwd = 2)
abline(h = logLik(fit_spaMM_REML) - 0.5*qchisq(0.95, 1), col = "red", lty = 2, lwd = 2)
```


## Likelihood profiling 1 parameter: intercept

```{r profile for intercept, fig.align = "center", fig.width = 4, fig.height = 4, fig.show = "hold"}
logLik_profile <- sapply(candidate_intercept_u, function(intercept)
  logLik(lm(size ~ 0 + humans_eaten + offset(rep(intercept, nrow(Alien))), data = Alien)))
plot(logLik_profile ~ candidate_intercept_u, type = "l")
abline(v = 50, col = "green", lwd = 2)
abline(v = coef(fit_stats)[1], col = "blue", lwd = 2)
abline(h = logLik(fit_stats) - 0.5*qchisq(0.95, 1), col = "red", lty = 2, lwd = 2)
```


## Likelihood profiling 2 parameters

```{r profile betas, fig.align = "center", echo = FALSE, results = "hide", fig.height = 5.5, fig.width = 5.5}
candidates$logLik <- NA

for (i in 1:nrow(candidates)) { ## could use sapply here too
  fit_temp <- lm(size ~  0 + offset(candidates[i, 1] + candidates[i, 2] * humans_eaten), data = Alien)
  candidates[i, "logLik"] <- logLik(fit_temp)
}

par(las = 1)
with(candidates, contour(candidate_intercept_u, candidate_slope_u,
  matrix(candidates$logLik, nrow = length(candidate_intercept_u)), nlevels = 15,
  xlab = "slope", ylab = "intercept"))
points(fit_spaMM_ML$fixef["(Intercept)"], fit_spaMM_ML$fixef["humans_eaten"],
        col = "blue", pch = 4, lwd = 2, cex = 3)
points(50, 1.5, col = "green", pch = 4, lwd = 2, cex = 3)

limit <- c(logLik(fit_stats) - 0.5*qchisq(0.95, df = 2))
with(candidates, contour(candidate_intercept_u, candidate_slope_u,
  matrix(candidates$logLik, nrow = length(candidate_intercept_u)),
  levels = limit, add = TRUE, col = "red", lwd = 2))
```


## Confidence intervals by likelihood profiling

* Benefit: not based on SE, so works well even if error is not gaussian or if SE is badly estimated.
* Cost: uses the chi-squared distribution, which is an asymptotic approximation, so it needs a lot of observations.

```{r CI by profile}
diff_logLik_intercept <- function(intercept, fit) {
  newfit <- lm(size ~ 0 + humans_eaten + offset(rep(intercept, nrow(fit$model))), data = fit$model)
  logLik_newfit <- logLik(newfit)[[1]]
  logLik_goal <- logLik(fit)[[1]] - 0.5*qchisq(0.95, df = 1)
  abs(logLik_newfit - logLik_goal)
}
```

```{r CI by profile2}
CI_prof_intercept <- function(fit) {
  lwr <- optimise(diff_logLik_intercept, interval = c(coef(fit)[1] - 10, coef(fit)[1]),
                  fit = fit)
  upr <- optimise(diff_logLik_intercept, interval = c(coef(fit)[1], coef(fit)[1] + 10),
                  fit = fit)
  c(lwr = lwr$minimum, upr = upr$minimum)
}
```

```{r CI by profile3}
CI_prof_intercept(fit_stats)
```


# Confidence intervals of the mean response

## 95% CI for the mean response

It shows where most mean responses from fit of other samples from the same population (and of the same size) should fall:

```{r CI predVar, fig.align="center", fig.width=3.5, fig.height=3.5}
pred <- data.frame(humans_eaten = seq(1, 12, 0.1))
pred <- cbind(pred, predict(fit_stats, newdata = pred, interval = "confidence"))
plot(size ~ humans_eaten, data = Alien)
points(fit ~ humans_eaten, data = pred, lty = 1, lwd = 2, col = "blue", type = "l")
points(upr ~ humans_eaten, data = pred, lty = 2, lwd = 2, col = "blue", type = "l")
points(lwr ~ humans_eaten, data = pred, lty = 2, lwd = 2, col = "blue", type = "l")
```


## Computing 95% CI for the mean response

Not available for all linear models out of the box but it is easy for `lm()`:
```{r compute predVar}
predict(fit_stats, newdata = data.frame(humans_eaten = 4:5), interval = "confidence")
```

Or, to follow a recipe that will become useful for GLMs:
```{r compute predVar 2}
pred <- predict(fit_stats, newdata = data.frame(humans_eaten = 4:5), interval = "confidence", se.fit = TRUE)
rbind(c(pred$fit[1, "fit"] + quantile_min * pred$se.fit[1],  ## the same quantile from the Student-t distrib
        pred$fit[1, "fit"] + quantile_max * pred$se.fit[1]), ## that we have seen before!
      c(pred$fit[2, "fit"] + quantile_min * pred$se.fit[2], 
        pred$fit[2, "fit"] + quantile_max * pred$se.fit[2]))
```


## Computing 95% CI for the mean response

It is also quite easy with models fitted with **{spaMM}**:
```{r compute predVar spaMM}
pred <- data.frame(humans_eaten = 4:5)
pred$fit <- predict(fit_spaMM_ML, newdata = pred)
pred$se.fit <- get_predVar(fit_spaMM_REML, newdata = pred)^0.5  ## REML!
rbind(c(pred$fit[1] + quantile_min * pred$se.fit[1],  ## the same quantile from the Student-t distrib
        pred$fit[1] + quantile_max * pred$se.fit[1]), ## that we have seen before!
      c(pred$fit[2] + quantile_min * pred$se.fit[2], 
        pred$fit[2] + quantile_max * pred$se.fit[2]))
```

<!--
## Computing 95% CI for the mean response

```{r compute predVar2}
pred$se.fit^2 ## prediction variance
(X <- cbind(c(1, 1), 4:5))  ## design matrix
(vcov.means <- X %*% vcov(fit_stats) %*% t(X))  ## covariances for predicted values
diag(vcov.means)
```
-->


# Prediction interval

## 95% Prediction Interval

It shows where most new observations from the same population should fall:

```{r respVar, fig.align="center", fig.width=3.5, fig.height=3.5}
pred <- data.frame(humans_eaten = seq(1, 12, 0.1))
pred <- cbind(pred, predict(fit_stats, newdata = pred, interval = "prediction"))
plot(size ~ humans_eaten, data = Alien)
points(fit ~ humans_eaten, data = pred, lty = 1, lwd = 2, col = "red", type = "l")
points(upr ~ humans_eaten, data = pred, lty = 2, lwd = 2, col = "red", type = "l")
points(lwr ~ humans_eaten, data = pred, lty = 2, lwd = 2, col = "red", type = "l")
```


## Computing 95% PI

With `lm()`:
```{r compute respVar}
pred <- predict(fit_stats, newdata = data.frame(humans_eaten = 4:5), interval = "prediction", se.fit = TRUE)
pred$fit
se.pred <- sqrt(pred$se.fit^2 + pred$residual.scale^2) ## residual.scale = sigma error
rbind(c(pred$fit[1, "fit"] + quantile_min * se.pred[1],
        pred$fit[1, "fit"] + quantile_max * se.pred[1]),
      c(pred$fit[2, "fit"] + quantile_min * se.pred[2],
        pred$fit[2, "fit"] + quantile_max * se.pred[2]))
```


## Computing 95% PI

With **{spaMM}**:
```{r compute respVar spaMM}
pred <- data.frame(humans_eaten = 4:5)
pred$fit <- predict(fit_spaMM_ML, newdata = pred)
se.pred <- get_respVar(fit_spaMM_REML, newdata = pred, var = "respVar")^0.5
rbind(c(pred[1, "fit"] + quantile_min * se.pred[1],
        pred[1, "fit"] + quantile_max * se.pred[1]),
      c(pred[2, "fit"] + quantile_min * se.pred[2],
        pred[2, "fit"] + quantile_max * se.pred[2]))
```


## What you need to remember

* what point estimates are
* that point estimates are random variables
* that estimates are not necessarily independent from each other
* what 95% Confidence Intervals are
* that there are 3 main ways to compute 95% CI
* what the parametric bootstrap is
* what likelihood profiling is
* what statistical coverage is
* what 95% CI on the mean response are
* what 95% Prediction Intervals are

# Table of contents

## The Linear Model: LM

* 2.0 [Introduction](./LM_intro.html)
* 2.1 [Fitting procedure](./LM_fitting.html)
* 2.2 [Uncertainty in point estimates](./LM_uncertainty.html)
* 2.3 [Tests](./LM_tests.html)
* 2.4 [Assumptions and Outliers](./LM_assumptions.html)
* 2.5 [Let's practice more](./LM_practice.html)

<br>

<div align="right">
[Back to main menu](./Title.html#2)
</div>

