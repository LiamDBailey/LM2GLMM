---
title: "LM: Uncertainty in point estimates"
author: "Alexandre Courtiol"
date: "`r Sys.Date()`"
output:
  ioslides_presentation:
    widescreen: true
    smaller: true
vignette: >
  %\VignetteIndexEntry{2.2 Uncertainty in point estimates}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
---

```{r setup, include=FALSE}
library(LM2GLMM)
library(spaMM)
library(lattice)
library(mvtnorm)
library(rgl)
knitr::knit_hooks$set(webgl = hook_webgl) ## for rgl
knitr::opts_chunk$set(cache = TRUE, cache.path = "./cache_knitr/LM_uncertainty/", fig.path = "./fig_knitr/LM_uncertainty/", error = TRUE)
```

## You will learn in this session

* that point estimates are random variables with estimated means and variances
* that estimates for $\beta$ are Gaussian and the estimate of the error variance is gamma distributed
* what parametric bootstrap is
* what 95% Confidence Intervals are
* that boundaries for 95% CI on $\widehat{\beta}$ are given by the Student distribution
* what statistical coverage is
* what the 95% CI on the mean response is
* what 95% Prediction Intervals are
* what likelihood profiling is
* that estimates are not necessarily independent from each other
* that there are 3 ways to get 95% CI for LM


# Introduction

## Summary of point estimates

```{r point estimates}
set.seed(123L)
Alien <- data.frame(humans_eaten = sample(1:12))
Alien$size <- rnorm(n = 12, mean = 50 + 1.5*Alien$humans_eaten, sd = sqrt(25))

mod_stats <- lm(size ~ humans_eaten, data = Alien)
c(coef(mod_stats), sigma2_error <- summary(mod_stats)$sigma^2)

mod_spaMM_ML   <- fitme(size ~ humans_eaten, data = Alien, method = "ML")
mod_spaMM_REML <- fitme(size ~ humans_eaten, data = Alien, method = "REML")
c(mod_spaMM_ML$fixef, sigma2 = mod_spaMM_REML$phi)  ## fixef are same for REML as estimated with ML too
```

### Those are point estimates. Estimates are random variables!

```{r sigma2 resid}
sigma2_resid <- mod_spaMM_ML$phi ## stored for later (but it is not an estimate!)
```

# Theoretical distributions of point estimates

## Covariances of the estimates

```{r vcov}
XTX <- crossprod(model.matrix(mod_stats))
## XTX/sigma2_error is the Hessian (matrix of second derivative) of Lik(X)
## the inverse of the Hessian gives the covariance matrix
sigma2_error * solve(XTX)  
vcov(mod_stats)
vcov(mod_spaMM_REML)  ## don't use the ML fit here!
```

## The estimates of $\beta$ are Gaussian

<br>

```{r compute density betas}
candidate_intercept_u <- seq(from = 30, to = 70,  by = 0.1)
candidate_slope_u     <- seq(from =  0, to = 2.5, by = 0.1)

candidates <- expand.grid(candidate_intercept = candidate_intercept_u, candidate_slope = candidate_slope_u)

candidates$d <- dmvnorm(x = candidates[, 1:2], mean = coef(mod_stats), sigma = vcov(mod_stats), log = FALSE)
```

## Density of the estimates for $\beta$

```{r plot rgl, webgl=TRUE, fig.align="center"}
library(rgl)  ## to make interactive plots!
with(data = candidates, plot3d(candidate_intercept, candidate_slope, d))
```

## Same plot with ```graphics```

```{r plot graphics, fig.align = "center", fig.height = 4, fig.width = 4}
contour(x = candidate_intercept_u, y = candidate_slope_u,
        z = matrix(candidates$d, nrow = length(candidate_intercept_u)),
        nlevels = 5, xlab = "intercept", ylab = "slope")
```

## The estimate of $\sigma^2$ is Gamma (asymptotically)

$\widehat{\sigma}^2$ follows a $\Gamma$ distribution with mean  = $\texttt{error variance}$ and var = $2 ( \texttt{error variance})^2 / (N-K)$.

[for $\Gamma$, mean = $\texttt{shape} \times \texttt{scale}$ and var = 
$\texttt{shape} \times \texttt{scale}^2$]

```{r gamma, fig.align = "center", fig.height = 4, fig.width = 4}
curve(dgamma(x, shape = mod_stats$df.residual/2, scale = 2*sigma2_error/mod_stats$df.residual),
    from = 0, to = 80, xlab = "sigma2_error", ylab = "probability density", lwd = 3)
```


# Comparing theoretical distributions to the reality

## A simulation function for the generating Aliens

```{r simulate alien fn}
simulate_Aliens
```


<div class="columns-2">

```{r alien dataset}
head(Alien)
```

<br>

```{r simulated dataset}
set.seed(123L)
head(simulate_Aliens())
```

</div>

## Distribution of the estimates for $\beta$

```{r redraw samples}
new_beta_estimates <- t(replicate(1000, coef(update(mod_stats, data = simulate_Aliens()))))
```

<div class="columns-2">

```{r plot ecdf intercept, fig.align = "center", fig.height = 4, fig.width = 4}
curve(pnorm(x, mean = coef(mod_stats)[1],
    sd = sqrt(vcov(mod_stats)[[1]])),
    from = 30, to = 60, ylab = "cdf", lwd = 3)
plot(ecdf(new_beta_estimates[, 1]), col = "red",
     add = TRUE)
```

```{r plot ecdf slope, fig.align = "center", fig.height = 4, fig.width = 4}
curve(pnorm(x, mean = coef(mod_stats)[2],
    sd = sqrt(vcov(mod_stats)[[4]])),
    from = 0, to = 3, ylab = "cdf", lwd = 3)
plot(ecdf(new_beta_estimates[, 2]), col = "red",
     add = TRUE)
```

</div>

## Distribution of the estimate for $\sigma^2$

```{r plot ecdf sigma2, fig.align = "center", fig.height = 4, fig.width = 4}
new_sigma2_error <- t(replicate(1000, summary(update(mod_stats, data = simulate_Aliens()))$sigma^2))
curve(pgamma(x, shape = mod_stats$df.residual/2, scale = 2*summary(mod_stats)$sigma^2/mod_stats$df.residual),
    from = 0, to = 80, ylab = "cdf", lwd = 3)
plot(ecdf(new_sigma2_error), col = "red", add = TRUE)
```



# Comparing theoretical distributions to parametric bootstrap


## Comparison with parametric bootstrap

```{r betas param boot}
newYs <- simulate(mod_stats, nsim = 5000)  ## generate new values for the response variable
res_sim <- t(coef(lm(as.matrix(newYs) ~ humans_eaten, data = Alien)))
```

<div class="columns-2">

```{r plot intercept param boot, fig.align = "center", fig.height = 4, fig.width = 4}
curve(pnorm(x, mean = coef(mod_stats)[1],
    sd = sqrt(vcov(mod_stats)[[1]])),
    from = 30, to = 60, ylab = "cdf", lwd = 3)
plot(ecdf(res_sim[, 1]), col = "red", add = TRUE)
```

```{r plot slope param boot, fig.align = "center", fig.height = 4, fig.width = 4}
curve(pnorm(x, mean = coef(mod_stats)[2],
    sd = sqrt(vcov(mod_stats)[[4]])),
    from = 0, to = 3, ylab = "cdf", lwd = 3)
plot(ecdf(res_sim[, 2]), col = "red", add = TRUE)
```

</div>

## Same in 2D

```{r plot 2D betas param boot, fig.align = "center", fig.height = 4, fig.width = 4, results = "hide"}
with(candidates, contour(candidate_intercept_u, candidate_slope_u,
  matrix(d, nrow = length(candidate_intercept_u)), col = "transparent", xlab = "intercept", ylab = "slope"))
points(res_sim[, "(Intercept)"], res_sim[, "humans_eaten"], col = "red", pch = 1, cex = 0.5, lwd = 0.2)
with(candidates, contour(candidate_intercept_u, candidate_slope_u,
  matrix(d, nrow = length(candidate_intercept_u)), nlevels = 4, add = TRUE))
```

## Practice

<br>

### Compute the distribution of the estimate of the error variance by parametric bootstrap and compare it to the theoretical result.

# Confidence intervals

## CI for $\widehat{\beta}$ with known variance {.build}

<font size = 6> $\widehat{\beta}\sim \mathcal{N}(\beta, \sigma_{\widehat{\beta}})$ </font>

<font size = 6> $z = \frac{\widehat{\beta} - \beta}{\sigma_{\widehat{\beta}}}\sim \mathcal{N}(0, 1)$ </font>

<font size = 6> 95% CI for $z = [\mathrm{Q}0.025_{\mathcal{N}}; \ \mathrm{Q}0.975_{\mathcal{N}} ]$ </font>

```{r quantile norm}
c(Q0.025_N = qnorm(0.025), Q0.975_N = qnorm(0.975))
```

<font size = 6> 95% CI for $\widehat{\beta} = [\widehat{\beta} + \mathrm{Q0.025}_{\mathcal{N}} \times \sigma_{\widehat{\beta}}; \ \widehat{\beta} + \mathrm{Q0.975}_{\mathcal{N}} \times \sigma_{\widehat{\beta}}]$ </font>

## CI for $\widehat{\beta}$ with estimated variance {.build}

<font size = 6> $\widehat{\beta}\sim \mathcal{N}(\beta, \sigma_{\widehat{\beta}})$ </font>

<font size = 6> $t = \frac{\widehat{\beta} - \beta}{\widehat{\sigma_{\widehat{\beta}}}}\sim \mathcal{t}_{N - K}$ </font> ($t$ = Student's t distribution)

<font size = 6> 95% CI for $t = [\mathrm{Q}0.025_{\mathcal{t}_{N - K}}; \ \mathrm{Q}0.975_{\mathcal{t}_{N - K}}]$ </font>

```{r quantile t}
c(Qt_0.025 = qt(0.025, df = 10), Qt_0.975 = qt(0.975, df = 10))  ## with N-K = 10 (also try with 1000)
```

<font size = 6> 95% CI for $\widehat{\beta} =$ </font>

<font size = 6> $[\widehat{\beta} + \mathrm{Q}0.025_{\mathcal{t}_{N - K}} \times \widehat{\sigma_{\widehat{\beta}}}; \ \widehat{\beta} + \mathrm{Q}0.975_{\mathcal{t}_{N - K}} \times \widehat{\sigma_{\widehat{\beta}}}]$ </font>



## Computing 95% CI for estimates

```{r CI Wald}
confint(mod_stats)
quantile_min <- qt(0.025, mod_stats$df.residual)
quantile_max <- qt(0.975, mod_stats$df.residual)
cbind(coef(mod_stats) + quantile_min * sqrt(diag(vcov(mod_stats))),
      coef(mod_stats) + quantile_max * sqrt(diag(vcov(mod_stats))))
```

## Testing the coverage of the 95% CI

```{r coverage CI Wald}
set.seed(1L)
mean(replicate(5000, sum(findInterval(confint(update(mod_stats, data = simulate_Aliens()))[1, ], 50)) == 1))
mean(replicate(5000, sum(findInterval(confint(update(mod_stats, data = simulate_Aliens()))[2, ], 1.5)) == 1))
```

## Computing 95% CI for estimates (param. boot.)

```{r CI confint for comp}
confint(mod_stats)  ## asymptotic (for comparison)
```

It still depends on the t-distribution but SE are no longer computed analytically:

```{r CI param boot}
ses <- t(apply(res_sim, 2, sd))  ## compute sd of estimates from parametric bootstrap
(confint_boot <- cbind(c(coef(mod_stats) + quantile_min * ses), c(coef(mod_stats) + quantile_max * ses)))
```

## Testing the coverage of the 95% CI (param. boot.)

```{r coverage CI param boot}
CIboot <- function(rep = 100){
  data <- simulate_Aliens()
  mod <- update(mod_stats, data = data)
  newYs <- simulate(mod, nsim = rep)
  res_sim <- t(coef(lm(as.matrix(newYs) ~ humans_eaten, data = data)))
  ses <- apply(res_sim, 2, sd)
  cbind(coef(mod) + quantile_min * ses, coef(mod) + quantile_max * ses)
}
set.seed(1L)
mean(replicate(5000, sum(findInterval(CIboot()[1, ], 50)) == 1))
mean(replicate(5000, sum(findInterval(CIboot()[2, ], 1.5)) == 1))
```

## 95% CI for the mean response

```{r CI predVar, fig.align="center", fig.width=4, fig.height=4}
pred <- data.frame(humans_eaten = seq(1, 12, 0.1))
pred <- cbind(pred, predict(mod_stats, newdata = pred, interval = "confidence"))
plot(size ~ humans_eaten, data = Alien)
points(fit ~ humans_eaten, data = pred, lty = 1, lwd = 2, col = "blue", type = "l")
points(upr ~ humans_eaten, data = pred, lty = 2, lwd = 2, col = "blue", type = "l")
points(lwr ~ humans_eaten, data = pred, lty = 2, lwd = 2, col = "blue", type = "l")
```

## Computing 95% CI for the mean response

```{r compute predVar}
predict(mod_stats, newdata = data.frame(humans_eaten = 4:5), interval = "confidence")
pred <- predict(mod_stats, newdata = data.frame(humans_eaten = 4:5), interval = "confidence", se.fit = TRUE)
rbind(c(pred$fit[1, "fit"] + quantile_min * pred$se.fit[1], 
        pred$fit[1, "fit"] + quantile_max * pred$se.fit[1]),
      c(pred$fit[2, "fit"] + quantile_min * pred$se.fit[2], 
        pred$fit[2, "fit"] + quantile_max * pred$se.fit[2]))
```

## Computing 95% CI for the mean response

```{r compute predVar2}
pred$se.fit^2 ## prediction variance
(X <- cbind(c(1, 1), 4:5))  ## design matrix
(vcov.means <- X %*% vcov(mod_stats) %*% t(X))  ## covariances for predicted values
diag(vcov.means)
```

# Prediction interval

## 95% Prediction Interval

```{r respVar, fig.align="center", fig.width=4, fig.height=4}
pred <- data.frame(humans_eaten = seq(1, 12, 0.1))
pred <- cbind(pred, predict(mod_stats, newdata = pred, interval = "prediction"))
plot(size ~ humans_eaten, data = Alien)
points(fit ~ humans_eaten, data = pred, lty = 1, lwd = 2, col = "red", type = "l")
points(upr ~ humans_eaten, data = pred, lty = 2, lwd = 2, col = "red", type = "l")
points(lwr ~ humans_eaten, data = pred, lty = 2, lwd = 2, col = "red", type = "l")
```

## Computing 95% PI

```{r compute respVar}
pred <- predict(mod_stats, newdata = data.frame(humans_eaten = 4), interval = "prediction", se.fit = TRUE)
pred$fit
se.pred <- sqrt(pred$se.fit^2 + pred$residual.scale^2)
pred$fit[, "fit"] + quantile_min * se.pred
pred$fit[, "fit"] + quantile_max * se.pred
pred$residual.scale^2 == summary(mod_stats)$sigma^2  ## estimate of the error variance
```

# Likelihood profiling

## Computing the likelihood for specific parameters

```{r logLik fixed}
logLik(lm(size ~ 0 + offset(50 + 1.5 * humans_eaten), data = Alien))

mod_spaMM_fix <- fitme(size ~ 0 + offset(50 + 1.5 * humans_eaten), fixed = list(phi = 25), data = Alien)
mod_spaMM_fix$APHLs$p_v
```

## Likelihood profiling 1 parameter: $\sigma^2$

```{r profile sigma2, fig.align = "center", fig.width = 4, fig.height = 4}
mod_spaMM_allfix <- fitme(size ~ humans_eaten, fixed = list(phi = 25), data = Alien)
candidate_sigma2 <- seq(10, 70, 0.5)
logLik_profile <- sapply(candidate_sigma2, function(sigma2) 
  update(mod_spaMM_allfix, fixed = list(phi = sigma2))$APHLs$p_v)
plot(logLik_profile ~ candidate_sigma2, type = "l")
abline(v = 25, col = "green", lwd = 2)
abline(v = mod_spaMM_ML$phi, col = "blue", lwd = 2)
```

## Likelihood profiling 1 parameter: intercept

```{r profile for intercept, fig.align = "center", fig.width = 4, fig.height = 4, fig.show = "hold"}
# candidate_intercept_u was a sequence of values defined back on slide 7 (could be nice for clarity to redefine it here)
logLik_profile <- sapply(candidate_intercept_u, function(intercept)
  logLik(lm(size ~ 0 + humans_eaten + offset(rep(intercept, nrow(Alien))), data = Alien)))
plot(logLik_profile ~ candidate_intercept_u, type = "l")
abline(v = 50, col = "green", lwd = 2)
abline(v = coef(mod_stats)[1], col = "blue", lwd = 2)
#abline(v = confint(mod_stats)[1, ], col = "purple", lty = 2, lwd = 2)
#abline(h = logLik(mod_stats) - 0.5*qchisq(0.95, 1), col = "red", lty = 2, lwd = 2)
```

## Likelihood profiling 2 parameters: plot

```{r profile betas, fig.align = "center", echo = FALSE, results = "hide", fig.height = 5.5, fig.width = 5.5}
candidates$logLik <- NA

for (i in 1:nrow(candidates)) {
  mod_temp <- lm(size ~  0 + offset(candidates[i, 1] + candidates[i, 2] * humans_eaten), data = Alien)
  candidates[i, "logLik"] <- logLik(mod_temp)
}

par(las = 1)
with(candidates, contour(candidate_intercept_u, candidate_slope_u,
  matrix(candidates$logLik, nrow = length(candidate_intercept_u)), nlevels = 15,
  xlab = "slope", ylab = "intercept"))
points(mod_spaMM_ML$fixef["(Intercept)"], mod_spaMM_ML$fixef["humans_eaten"],
        col = "blue", pch = 4, lwd = 2, cex = 3)
points(50, 1.5, col = "green", pch = 4, lwd = 2, cex = 3)

#limit <- c(logLik(mod_stats) - 0.5*qchisq(0.95, df = 2))
#with(candidates, contour(candidate_intercept_u, candidate_slope_u,
#  matrix(candidates$logLik, nrow = length(candidate_intercept_u)),
#  levels = limit, add = TRUE, col = "red", lwd = 2))
```


## Likelihood profiling 2 parameters: code

```{r profile betas bis, eval = FALSE}
candidates$logLik <- NA

for (i in 1:nrow(candidates)) {
  mod_temp <- lm(size ~  0 + offset(candidates[i, 1] + candidates[i, 2] * humans_eaten), data = Alien)
  candidates[i, "logLik"] <- logLik(mod_temp)
}

par(las = 1)
with(candidates, contour(candidate_intercept_u, candidate_slope_u,
                         matrix(candidates$logLik, nrow = length(candidate_intercept_u)),
                         nlevels = 15, xlab = "slope", ylab = "intercept"))
points(mod_spaMM_ML$fixef["(Intercept)"], mod_spaMM_ML$fixef["humans_eaten"],
       col = "blue", pch = 4, lwd = 2, cex = 3)
points(50, 1.5, col = "green", pch = 4, lwd = 2, cex = 3)

#limit <- c(logLik(mod_stats) - 0.5*qchisq(0.95, df = 2))
#with(candidates, contour(candidate_intercept_u, candidate_slope_u,
#  matrix(candidates$logLik, nrow = length(candidate_intercept_u)),
#  levels = limit, add = TRUE, col = "red", lwd = 2))
```

## Confidence intervals by likelihood profiling

* Benefit: not based on SE, so works well even if error is not gaussian or if SE is badly estimated.
* Cost: uses the chi-squared distribution, which is an asymptotic approximation, so it needs a lot of observations.

```{r CI by profile intercept}
where.is.limit.inter <- function(intercept, model_ref) {
  logLik_mod <- logLik(lm(size ~ 0 + humans_eaten + offset(rep(intercept, nrow(model_ref$model))),
                            data = model_ref$model))[[1]]
  logLik_goal <- logLik(model_ref)[[1]] - 0.5*qchisq(0.95, df = 1)
  return(abs(logLik_mod - logLik_goal))}
CI_intercept <- function(model_ref) {
  lwr <- optimise(where.is.limit.inter, interval = c(coef(model_ref)[1] - 10, coef(model_ref)[1]),
                  model_ref = model_ref)
  upr <- optimise(where.is.limit.inter, interval = c(coef(model_ref)[1], coef(model_ref)[1] + 10),
                  model_ref = model_ref)
  return(c(lwr = lwr$minimum, upr = upr$minimum))}
rbind("using SE" = confint(mod_stats)[1, ], "using SE boot" = confint_boot[1, ],
      "using profile" = CI_intercept(mod_stats))
```

## Same for the slope

```{r CI by profile slope}
where.is.limit.slope <- function(slope, model_ref) {
  logLik_mod <- logLik(lm(size ~ 1 + offset(slope * humans_eaten),
                            data = model_ref$model))[[1]]
  logLik_goal <- logLik(model_ref)[[1]] - 0.5*qchisq(0.95, df = 1)
  return(abs(logLik_mod - logLik_goal))
}

CI_slope <- function(model_ref) {
  lwr <- optimise(where.is.limit.slope, interval = c(coef(model_ref)[2] - 1, coef(model_ref)[2]),
                  model_ref = model_ref)
  upr <- optimise(where.is.limit.slope, interval = c(coef(model_ref)[2], coef(model_ref)[2] + 1),
                  model_ref = model_ref)
  return(c(lwr = lwr$minimum, upr = upr$minimum))
}

rbind("using SE" = confint(mod_stats)[2, ], "using SE boot" = confint_boot[2, ],
      "using profile" = CI_slope(mod_stats))
```

## Testing the coverage of the 95% CI by profile

```{r coverage CI profile}
set.seed(1L); n.replicates <- 1000
mean(replicate(n.replicates, sum(findInterval(CI_intercept(lm(size ~ humans_eaten,
    data = simulate_Aliens())), 50)) == 1))
mean(replicate(n.replicates, sum(findInterval(CI_slope(lm(size ~ humans_eaten,
    data = simulate_Aliens())), 1.5)) == 1))

mean(replicate(n.replicates, sum(findInterval(CI_intercept(lm(size ~ humans_eaten,
    data = simulate_Aliens(N = 500))), 50)) == 1))
mean(replicate(n.replicates, sum(findInterval(CI_slope(lm(size ~ humans_eaten,
    data = simulate_Aliens(N = 500))), 1.5)) == 1))
```


## What you need to remember

* that point estimates are random variables with estimated means and variances
* that estimates for $\beta$ are Gaussian and the estimate of the error variance is Gamma distributed
* what parametric bootstrap is
* what 95% Confidence Intervals are
* that boundaries for 95% CI on $\widehat{\beta}$ are given by the Student distribution
* what statistical coverage is
* what the 95% CI on the mean response is
* what 95% Prediction Intervals are
* what likelihood profiling is
* that estimates are not necessarily independent from each other
* that there are 3 ways to get 95% CI for LM

# Table of contents

## The Linear Model: LM

* 2.0 [Introduction](./LM_intro.html)
* 2.1 [Point estimates](./LM_point_estimates.html)
* 2.2 [Uncertainty in point estimates](./LM_uncertainty.html)
* 2.3 [Tests](./LM_tests.html)
* 2.4 [Assumptions and Outliers](./LM_assumptions.html)
* 2.5 [Let's practice more](./LM_practice.html)


