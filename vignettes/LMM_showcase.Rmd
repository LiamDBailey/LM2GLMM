---
title: "LMM: A showcase of some useful applications"
author: "Alexandre Courtiol"
date: "`r Sys.Date()`"
output:
  ioslides_presentation:
    widescreen: true
    smaller: true
vignette: >
  %\VignetteIndexEntry{4.3 A showcase of some useful applications of LMM}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
library(LM2GLMM)
library(spaMM)
library(lme4)
library(car)
spaMM.options(nb_cores = 4L)
options(width = 120)
knitr::opts_chunk$set(cache = TRUE, cache.path = "./cache_knitr/LMM_showcase/", fig.path = "./fig_knitr/LMM_showcase/", fig.width = 5, fig.height = 5, fig.align = "center")
```


## Mixed-effects models

* 4.0 [Introduction to LMM](./LMM_intro.html)
* 4.1 [Random effects](./LMM_random.html)
* 4.2 [Solving LM problems using LMM](./LMM_solving_pb.html)
* 4.3 [A showcase of some useful applications](./LMM_showcase.html)
* 4.4 [Introduction to GLMM](./GLMM_intro.html)
* 4.5 [More complex mixed models](./MM_more.html)


## You will learn in this session

* how to estimate heritability
* how to perform phylogenetic regressions
* how to perform meta-analyses
* that mixed models can do a lot, but that they are a bit tedious


# Studying genetic variation using LMM

## The animal model

### Nothing but a simple LMM:

$$ y_i = \mu + a_i + e_i$$

with:

* $\mu$ the population mean
* $a_i$ the breeding value (i.e. the effects of the $i$'s genotype relative to $\mu$)
* $e_i$ a residual term.

<br>

The variance of the breeding values is the additive genetic variance $V_\text{A}$.

The additive genetic covariance between two individuals = $\text{A}V_\text{A}$, where $\text{A}$ is the relatedness matrix.


## The relatedness matrix

<center>
<img src="./relatedness_matrix.png" alt="relatedness" style="width: 750px;"/>
</center>


## The Gryphon dataset

<center>
<img src="./AnimalModel.png" alt="Gryphon" style="width: 750px;"/>

<img src="./Gryphon.jpg" alt="Gryphon" style="width: 500px;"/>
</center>

## Building the matrix A

```{r}
tail(Gryphon$pedigree)
library(nadiv)
A <- as(makeA(Gryphon$pedigree), "matrix")
colnames(A) <- rownames(A) <- Gryphon$pedigree$ID
A[1305:1309, 1296:1309]
```

## Fiting a simple Animal Model

```{r animal model}
library(spaMM)
system.time(mod1 <- fitme(BWT ~ 1 + corrMatrix(1|ID), corrMatrix = A, data = Gryphon$data, method = "REML"))
(h2 <- as.numeric(mod1$lambda / (mod1$lambda + mod1$phi)))
```


## Fiting a more complex Animal Model

```{r animal model 2}
Gryphon$data$sex    <- factor(Gryphon$data$SEX)
Gryphon$data$year   <- factor(Gryphon$data$BYEAR)
Gryphon$data$mother <- factor(Gryphon$data$MOTHER)

system.time(
  mod2 <- fitme(BWT ~ sex + (1|year) + (1|mother) + corrMatrix(1|ID), corrMatrix = A,
                data = Gryphon$data, method = "REML")
)

h2 <- as.numeric(mod2$lambda["ID"]     / (sum(mod2$lambda) + mod2$phi))
m2 <- as.numeric(mod2$lambda["mother"] / (sum(mod2$lambda) + mod2$phi))

round(rbind("heritability" = h2, "maternal effect size" = m2), 3)
```


## Predicting the breeding values ($a_i$)

```{r, fig.height=3.5, fig.width=4}
curve(dnorm(x, sd = sqrt(as.numeric(mod2$lambda["ID"]))), from = -3, to = 3, las = 1,
      ylab = "pdf", xlab = "predicted breeding value")
BLUPs <- ranef(mod2)$"corrMatrix(1 | ID)"
points(dnorm(BLUPs, sd = sqrt(as.numeric(mod2$lambda["ID"]))) ~ BLUPs, col = "blue", type = "h", lwd = 0.1)
```

Never do statistics on BLUPs! Neglecting the uncertainty associated to these predictions is wrong.

Since BLUPs are here not added to fitted values, REML fit is the proper way to get them!

## Predicting the breeding values ($a_i$)

```{r}
plot(BLUPs ~ scale(mod2$data$BWT), ylab = "Predicted breeding values", xlab = "Scaled phenotypic values")
```


# Phylogenetic regressions


## The ```ade4::carni70``` dataset

```{r}
library(ade4)
data(carni70)
carni70$tab
```


## The phylogeny

```{r}
library(ape)
tree <- read.tree(text = carni70$tre)
plot(tree, cex = 0.3)
```


## Turning a tree into a correlation matrix

```{r}
(corrM <- vcv(tree, model = "Brownian", corr = TRUE))
```


## Fitting the phylogenetic regression model

```{r}
carni70$tab$sp <- factor(rownames(corrM))
(mod_carni <- fitme(range ~ size + corrMatrix(1|sp), corrMatrix = corrM, data = carni70$tab))
```


## Testing the fixed effects

```{r}
mod_carni_no_size <- fitme(range ~ 1 + corrMatrix(1|sp), corrMatrix = corrM, data = carni70$tab)
anova(mod_carni, mod_carni_no_size)
```


## Comparison with the traditional ```gls``` fit

```{r, message = FALSE}
library(nlme)
rownames(carni70$tab) <- rownames(corrM)
(mod_carni2 <- gls(range ~ size, correlation = corBrownian(1, phy = tree), method = "ML", data = carni70$tab))
```

A benefit of using a proper (G)LMM instead of the Generalized Least Squares is that we could also consider other random effects and model a non gaussian response (GLMM).
The function ```fitme()``` does that, but ```gls()``` cannot.


## Comparison with the traditional ```gls``` fit

```{r}
mod_carni2_no_size <- gls(range ~ 1, correlation = corBrownian(1, tree), method = "ML", data = carni70$tab)
anova(mod_carni2, mod_carni2_no_size)
```

<br>

Note: differences between LMM and GLS are expected.

# Meta-analyses

## Example: The ```metafor::dat.bcg``` dataset

### Studies on the effectiveness of the BCG vaccine against Tuberculosis

```{r, message = FALSE}
library(metafor)
dat.bcg
```


## We compute an effect size

### Let's compute the relative risks and associated sampling variances:
```{r}
dat.bcg$RR  <- with(dat.bcg, log((tpos/(tpos + tneg)) / (cpos/(cpos + cneg))))
dat.bcg$sampling.var <- with(dat.bcg, 1/tpos - 1/tneg + 1/cpos - 1/cneg)
dat.bcg
```


## We fit the model with ```metafor```

```{r}
(mod <- rma(yi = RR ~ factor(alloc) + year + ablat, vi = sampling.var, data = dat.bcg, method = "REML"))
```


## We fit the model with ```spaMM```

```{r}
dat.bcg$study <- factor(dat.bcg$trial)
(mod_spaMM <- fitme(RR ~ factor(alloc) + year + ablat + (1|study), data = dat.bcg,
                    fixed = list(phi = dat.bcg$sampling.var), method = "REML"))
```


## Comparing outputs

```{r}
round(c(tau2_metafor = mod$tau2, lambda_spaMM = mod_spaMM$lambda[[1]]), 4)  ## heterogeneity between studies

mod_spaMMRE <- fitme(RR ~ 1 + (1|study), data = dat.bcg,
                     fixed = list(phi = dat.bcg$sampling.var), method = "REML")

R2_spaMM <- 100 * (mod_spaMMRE$lambda[[1]] - mod_spaMM$lambda[[1]]) / mod_spaMMRE$lambda[[1]]
round(c(R2_metafor = mod$R2, R2_spaMM = R2_spaMM), 4)  ## amount of heterogeneity accounted for by fixed effects
```

## Comparing outputs

```{r}
c(mod$I2, mod$H2, mod$QE) ## from metafor, see ?print.rma.uni for details

get_meta_metrics <- function(model, vi) {
  wi <- 1/vi  ## weights = inverse of sampling variance
  k <- length(model$ranef)  ## number of groups in random term (here number of studies)
  p <- length(model$fixef)  ## number of fixed effect parameters
  W <- diag(wi, nrow = k, ncol = k)  ## matrix of weights
  X <- as.matrix(as.data.frame(model$X.pv))  ## design matrix
  stXWX <- solve(t(X) %*% W %*% X)  ## weighted vcov of estimates
  P <- W - W %*% X %*% stXWX %*% crossprod(X, W)  ## weighted vcov of ??
  vi.avg <- (k - p) / sum(diag(P))
  I2 <- as.numeric(100 * model$lambda / (vi.avg + model$lambda) )
  H2 <- as.numeric((vi.avg + model$lambda) / vi.avg)
  QE <- max(0, c(crossprod(model$y, P) %*% model$y))
  return(c(I2 = I2, H2 = H2, QE = QE, vi.avg = vi.avg))
}

get_meta_metrics(mod_spaMM, dat.bcg$sampling.var) ## add vi.avg: weighted mean within study sampling variance
```


## Nice plots with ```metafor```

```{r, fig.width = 6, fig.height = 5.5}
metafor::plot.rma.uni(mod)  ## or just plot(mod)
```


## Can we do abstraction of fixed effects?

```{r}
mod_spaMM2    <- fitme(RR ~ factor(alloc) + year + ablat + (1|study), data = dat.bcg,
                       fixed = list(phi = dat.bcg$sampling.var))
mod_spaMM2_H0 <- fitme(RR ~ 1 + (1|study), data = dat.bcg, fixed = list(phi = dat.bcg$sampling.var))
anova(mod_spaMM2, mod_spaMM2_H0)
```


## Can we do abstraction of fixed effects?

```{r test for metafor}
res.boot <- anova(mod_spaMM2, mod_spaMM2_H0, boot.repl = 1000)
```

## Can we do abstraction of fixed effects?

```{r}
res.boot
```


## Can we do abstraction of fixed effects?

```{r}
(mod2 <- rma(yi = RR ~ factor(alloc) + year + ablat, vi = sampling.var, data = dat.bcg, method = "ML"))
```


## Can we do abstraction of fixed effects?

```{r}
(mod3 <- rma(yi = RR ~ factor(alloc) + year + ablat, vi = sampling.var, data = dat.bcg, method = "ML",
             test = "knha"))
```


## Does vaccination work?

```{r}
mod_spaMM3    <- fitme(RR ~ 1 + (1|study), data = dat.bcg, fixed = list(phi = dat.bcg$sampling.var))
mod_spaMM3_H0 <- fitme(RR ~ 0 + (1|study), data = dat.bcg, fixed = list(phi = dat.bcg$sampling.var))
anova(mod_spaMM3, mod_spaMM3_H0)
```


## Does vaccination work?

```{r test for metafor 2}
res.boot2 <- anova(mod_spaMM3, mod_spaMM3_H0, boot.repl = 1000)
```


## Does vaccination work?

```{r}
res.boot2
```


## Does vaccination work?

```{r}
mod_spaMM3$fixef
get_intervals(mod_spaMM3, re.form = NA, intervals = "predVar")[1, ]
```


## Does vaccination work?

```{r}
(mod4 <- rma(yi = RR ~ 1, vi = sampling.var, data = dat.bcg, method = "ML"))
```


## Does vaccination work?

```{r}
forest(mod4)
```


## What you need to remember

* that mixed models can do a lot, but that they are a bit tedious


# Table of contents

## Mixed-effects models

* 4.0 [Introduction to LMM](./LMM_intro.html)
* 4.1 [Random effects](./LMM_random.html)
* 4.2 [Solving LM problems using LMM](./LMM_solving_pb.html)
* 4.3 [A showcase of some useful applications](./LMM_showcase.html)
* 4.4 [Introduction to GLMM](./GLMM_intro.html)
* 4.5 [More complex mixed models](./MM_more.html)

