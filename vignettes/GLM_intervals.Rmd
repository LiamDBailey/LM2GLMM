---
title: "GLM: Intervals & Tests"
author: "Alexandre Courtiol"
date: "`r Sys.Date()`"
output:
  ioslides_presentation:
    widescreen: true
    smaller: true
vignette: >
  %\VignetteIndexEntry{3.1 Intervals & Tests}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
---

```{r setup, include=FALSE}
library(LM2GLMM)
library(car)
library(MASS)
library(spaMM)
options(width = 120)
knitr::opts_chunk$set(cache = TRUE, cache.path = "./cache_knitr/GLM_uncertainty/", fig.path = "./fig_knitr/GLM_uncertainty/", fig.width = 4, fig.height = 4, fig.align = "center")
```

## You will learn in this session

* that estimates are still roughly normally distributed (but only roughly)
* how to compute intervals for GLM
* that intervals based on likelihood are best for family with known dispersion
* that established methods don't always work well, so you should always run tests
* that parametric bootstrap can outperform other methods when done properly
* that intervals on scale other than $\eta$ must be done by hand or using ```spaMM```
* that tests from summary tables are only reliable for the gaussian family
* that LR tests are best for family with known dispersion
* that LR tests by parametric bootstrap are best in all situations and easy to do with ```spaMM```


## Our data

```{r}
set.seed(1L)
Aliens <- simulate_Aliens_GLM()
head(Aliens)
attributes(Aliens)$param.eta$size
attributes(Aliens)$param.eta$blue_eyes
```


## Our toy models

<br>

```{r}
mod_gauss <- glm(size  ~ humans_eaten, family = gaussian(), data = Aliens)
mod_poiss <- glm(eggs  ~ humans_eaten, family = poisson(),  data = Aliens)
mod_binar <- glm(happy ~ humans_eaten, family = binomial(), data = Aliens)
mod_binom <- glm(cbind(blue_eyes, pink_eyes) ~ humans_eaten, family = binomial(), data = Aliens)
```

# Uncertainty in estimates

## Covariances between parameter estimates

### Poisson family

<br>

```{r}
X <- model.matrix(mod_poiss)
W <- matrix(0, ncol = nrow(mod_poiss$model), nrow = nrow(mod_poiss$model))
diag(W) <- mod_poiss$weights
t(X) %*% W %*% X
(XTWX <- crossprod(mod_poiss$R))
```

## Covariances between parameter estimates

### Poisson family

<br>

```{r}
vcov(mod_poiss)
phi <- 1
phi*solve(XTWX)
```

## Covariances between parameter estimates

### Gaussian family

<br>

```{r}
vcov(mod_gauss)
XTWX <- crossprod(mod_gauss$R)
phi <- mod_gauss$deviance / mod_gauss$df.residual
phi*solve(XTWX)
```

## Covariances between parameter estimates

### Binomial family (binary case)

<br>

```{r}
vcov(mod_binar)
XTWX <- crossprod(mod_binar$R)
phi <- 1
phi*solve(XTWX)
```

## Covariances between parameter estimates

### Binomial family (general case)

<br>

```{r}
vcov(mod_binom)
XTWX <- crossprod(mod_binom$R)
phi <- 1
phi*solve(XTWX)
```


## Distribution of parameter estimates

The parameter estimates are asymptotically normally distributed.

```{r}
new_betas <- t(replicate(1000, update(mod_gauss, data = simulate_Aliens_GLM())$coef))
```

<div class="columns-2">
```{r}
qqnorm(new_betas[, 1])
qqline(new_betas[, 1], col = "red", lwd = 2)
```

```{r}
qqnorm(new_betas[, 2])
qqline(new_betas[, 2], col = "red", lwd = 2)
```
</div>


## Distribution of parameter estimates

The parameter estimates are asymptotically normally distributed.

```{r}
new_betas <- t(replicate(1000, update(mod_poiss, data = simulate_Aliens_GLM())$coef))
```

<div class="columns-2">
```{r}
qqnorm(new_betas[, 1])
qqline(new_betas[, 1], col = "red", lwd = 2)
```

```{r}
qqnorm(new_betas[, 2])
qqline(new_betas[, 2], col = "red", lwd = 2)
```
</div>


## Distribution of parameter estimates

The parameter estimates are asymptotically normally distributed.

```{r}
new_betas <- t(replicate(1000, update(mod_binar, data = simulate_Aliens_GLM())$coef))
```

<div class="columns-2">
```{r}
qqnorm(new_betas[, 1])
qqline(new_betas[, 1], col = "red", lwd = 2)
```

```{r}
qqnorm(new_betas[, 2])
qqline(new_betas[, 2], col = "red", lwd = 2)
```
</div>


## Distribution of parameter estimates

The parameter estimates are asymptotically normally distributed.

```{r}
new_betas <- t(replicate(1000, update(mod_binom, data = simulate_Aliens_GLM())$coef))
```


<div class="columns-2">
```{r}
qqnorm(new_betas[, 1])
qqline(new_betas[, 1], col = "red", lwd = 2)
```

```{r}
qqnorm(new_betas[, 2])
qqline(new_betas[, 2], col = "red", lwd = 2)
```
</div>


# Confidence intervals on estimates

## 95% CI using Gaussian approximation

### Computation
```{r}
confint.approx <- function(mod, print = FALSE) {
  
  intervals <- cbind(lwr = (mod$coefficients + qnorm(0.025) *  sqrt(diag(vcov(mod)))),
                     upr = (mod$coefficients + qnorm(0.975) *  sqrt(diag(vcov(mod)))))
  
  if (print) print(intervals)
  name.response <- mod$terms[[2]]
  if (length(name.response) == 3) name.response <- name.response[[2]]
  true.intercept <- attributes(mod$data)$param.eta[[paste(name.response)]][1]
  true.slope <- attributes(mod$data)$param.eta[[paste(name.response)]][2]
  if (print) cat("\n true parameters in 95% CI? \n")
  
  c(true.intercept > intervals["(Intercept)", "lwr"] & true.intercept < intervals["(Intercept)", "upr"],
    true.slope > intervals["humans_eaten", "lwr"] & true.slope < intervals["humans_eaten", "upr"])
}
```


## 95% CI using Gaussian approximation

### Testing our function
```{r}
confint.approx(mod_poiss, print = TRUE)
```


## 95% CI using Gaussian approximation

### Coverage
```{r}
set.seed(1L)
replicate(5, confint.approx(update(mod_poiss, data = simulate_Aliens_GLM())))
```


## 95% CI using Gaussian approximation

### Coverage N = 100
```{r coverage1}
test_poiss <- replicate(1000, confint.approx(update(mod_poiss, data = simulate_Aliens_GLM())))
test_binar <- replicate(1000, confint.approx(update(mod_binar, data = simulate_Aliens_GLM())))
test_binom <- replicate(1000, confint.approx(update(mod_binom, data = simulate_Aliens_GLM())))
test_gauss <- replicate(1000, confint.approx(update(mod_gauss, data = simulate_Aliens_GLM())))
rbind(poiss = apply(test_poiss, 1, mean),
      binar = apply(test_binar, 1, mean),
      binom = apply(test_binom, 1, mean),
      gauss = apply(test_gauss, 1, mean))
```


## 95% CI using Gaussian approximation

### Coverage N = 15
```{r coverage1b, warning = FALSE}
test_poiss <- replicate(1000, confint.approx(update(mod_poiss, data = simulate_Aliens_GLM(N = 15))))
test_binar <- replicate(1000, confint.approx(update(mod_binar, data = simulate_Aliens_GLM(N = 15))))
test_binom <- replicate(1000, confint.approx(update(mod_binom, data = simulate_Aliens_GLM(N = 15))))
test_gauss <- replicate(1000, confint.approx(update(mod_gauss, data = simulate_Aliens_GLM(N = 15))))
rbind(poiss = apply(test_poiss, 1, mean, na.rm = TRUE),
      binar = apply(test_binar, 1, mean, na.rm = TRUE),
      binom = apply(test_binom, 1, mean, na.rm = TRUE),
      gauss = apply(test_gauss, 1, mean, na.rm = TRUE))
```


## 95% CI using Gaussian approximation

### Coverage N = 1000
```{r coverage1c, error = TRUE}
set.seed(1L)
test_poiss <- replicate(1000, confint.approx(update(mod_poiss, data = simulate_Aliens_GLM(N = 1000))))
test_binar <- replicate(1000, confint.approx(update(mod_binar, data = simulate_Aliens_GLM(N = 1000))))
test_binom <- replicate(1000, confint.approx(update(mod_binom, data = simulate_Aliens_GLM(N = 1000))))
test_gauss <- replicate(1000, confint.approx(update(mod_gauss, data = simulate_Aliens_GLM(N = 1000))))
rbind(poiss = apply(test_poiss, 1, mean),
      binar = apply(test_binar, 1, mean),
      binom = apply(test_binom, 1, mean),
      gauss = apply(test_gauss, 1, mean))
```


## 95% CI using Gaussian approximation

### Conclusion

The coverage is poor when dispersion parameters must be estimated on small datasets.

This will be a problem for gaussian() but also for other families we will see later (quasiXXX()).

When datasets are large, the coverage becomes good for the Gaussian case but it is a bit off for the other families.


## 95% CI on two parameters using Gaussian approximation

```{r, message = FALSE}
library(ellipse)
el <- ellipse(mod_poiss)
plot(el, type = "l")
```

## 95% CI using likelihood profiling

### Computation using MASS
```{r}
library(MASS)
confint(mod_poiss)
confint(mod_binar)
```


## 95% CI using likelihood profiling

### Computation using MASS
```{r}
prof <- profile(mod_poiss, alpha = (1 - 0.95)/4)  ## not sure why this alpha, but confint.glm does that
pro <- prof$`(Intercept)`
pro[1:3, ]
m <- update(mod_poiss, . ~ 0 + offset(-1.17095138 + 0.10732524 * humans_eaten))
sqrt((m$deviance - mod_poiss$deviance)/1)
sp <- spline(x = pro[, "par.vals"][, 1], y = pro[, 1])
approx(sp$y, sp$x, xout = qnorm(c(0.025, 0.975)))$y
```


## 95% CI using likelihood profiling

### Coverage of ```confint.glm```
```{r}
confint.profile <- function(mod, print = FALSE) {
  
  suppressMessages(intervals <- MASS:::confint.glm(mod))
  
  if (print) print(intervals)
  name.response <- mod$terms[[2]]
  if (length(name.response) == 3) name.response <- name.response[[2]]  ## for  binomial with cbind
  true.intercept <- attributes(mod$data)$param.eta[[paste(name.response)]][1]
  true.slope <- attributes(mod$data)$param.eta[[paste(name.response)]][2]
  if (print) cat("\n true parameters in 95% CI? \n")
  
  c(true.intercept > intervals["(Intercept)", "2.5 %"] & true.intercept < intervals["(Intercept)", "97.5 %"],
    true.slope > intervals["humans_eaten", "2.5 %"] & true.slope < intervals["humans_eaten", "97.5 %"])
}
```


## 95% CI using likelihood profiling

### Coverage N = 100
```{r  coverage2, message = FALSE, warning = FALSE}
set.seed(1L)
test_poiss <- replicate(1000, confint.profile(update(mod_poiss, data = simulate_Aliens_GLM())))
test_binar <- replicate(1000, confint.profile(update(mod_binar, data = simulate_Aliens_GLM())))
test_binom <- replicate(1000, confint.profile(update(mod_binom, data = simulate_Aliens_GLM())))
test_gauss <- replicate(1000, confint.profile(update(mod_gauss, data = simulate_Aliens_GLM())))
rbind(poiss = apply(test_poiss, 1, mean),
      binar = apply(test_binar, 1, mean),
      binom = apply(test_binom, 1, mean),
      gauss = apply(test_gauss, 1, mean))
```


## 95% CI using likelihood profiling

### Coverage  N = 15
```{r  coverage3, message = FALSE, warning = FALSE}
set.seed(1L)
test_poiss <- replicate(1000, confint.profile(update(mod_poiss, data = simulate_Aliens_GLM(N = 15))))
test_binar <- replicate(1000, confint.profile(update(mod_binar, data = simulate_Aliens_GLM(N = 15))))
test_binom <- replicate(1000, confint.profile(update(mod_binom, data = simulate_Aliens_GLM(N = 15))))
test_gauss <- replicate(1000, confint.profile(update(mod_gauss, data = simulate_Aliens_GLM(N = 15))))
rbind(poiss = apply(test_poiss, 1, mean, na.rm = TRUE),
      binar = apply(test_binar, 1, mean, na.rm = TRUE),
      binom = apply(test_binom, 1, mean, na.rm = TRUE),
      gauss = apply(test_gauss, 1, mean, na.rm = TRUE))
```


## 95% CI using likelihood profiling

### Coverage  N = 1000
```{r  coverage4, message = FALSE, warning = FALSE}
set.seed(1L)
test_poiss <- replicate(1000, confint.profile(update(mod_poiss, data = simulate_Aliens_GLM(N = 1000))))
test_binar <- replicate(1000, confint.profile(update(mod_binar, data = simulate_Aliens_GLM(N = 1000))))
test_binom <- replicate(1000, confint.profile(update(mod_binom, data = simulate_Aliens_GLM(N = 1000))))
test_gauss <- replicate(1000, confint.profile(update(mod_gauss, data = simulate_Aliens_GLM(N = 1000))))
rbind(poiss = apply(test_poiss, 1, mean),
      binar = apply(test_binar, 1, mean),
      binom = apply(test_binom, 1, mean),
      gauss = apply(test_gauss, 1, mean))
```


## 95% CI using likelihood profiling

### Conclusion

Using the likelihood profiling and an asymptotic cutoff does not seem (at least here) to be much better or worse than the simple Gaussian approximation for the distribution of parameter estimates when datasets are small or moderate.

The coverage gets a bit better when the dataset is large.

Recommendation: use t distribution for Gaussian case, profile confidence interval otherwise.

But again, you could also use the parametric bootstrap!


# Confidence intervals using parametric bootstrap

## 95% CI using parametric bootstrap

```{r}
set.seed(1)
new_betas <- replicate(100, {
  Aliens$newY <- as.matrix(simulate(mod_binar, 1))
  update(mod_binar, newY ~ .)$coefficients})
cbind(intercept = quantile(new_betas[1, ], c(0.025, 0.975)),
      slope = quantile(new_betas[2, ], c(0.025, 0.975)))
```

## 95% CI using parametric bootstrap

```{r}
confint.myboot <- function(mod, print = FALSE) {
  
  new_betas <- replicate(100, {
    mod$data$newY <- simulate(mod, 1)[, 1]
    update(mod, newY ~ ., data = mod$data)$coef})
 
  intervals <- rbind("(Intercept)" = quantile(new_betas[1, ], c(0.025, 0.975)),
      "humans_eaten" = quantile(new_betas[2, ], c(0.025, 0.975)))
  
  if (print) print(intervals)
  name.response <- mod$terms[[2]]
  if (length(name.response) == 3) name.response <- name.response[[2]]  ## for  binomial with cbind
  true.intercept <- attributes(mod$data)$param.eta[[paste(name.response)]][1]
  true.slope <- attributes(mod$data)$param.eta[[paste(name.response)]][2]
  if (print) cat("\n true parameters in 95% CI? \n")
  
  c(true.intercept > intervals["(Intercept)", 1] & true.intercept < intervals["(Intercept)", 2],
    true.slope > intervals["humans_eaten", 1] & true.slope < intervals["humans_eaten", 2])
}
```


## 95% CI using parametric bootstrap

### Coverage N = 100
```{r  coverage boot, message = FALSE, warning = FALSE}
set.seed(1L)
test_poiss <- replicate(1000, {
  new.data <- simulate_Aliens_GLM()
  mod <- update(mod_poiss, data = new.data)
  confint.myboot(mod)
  })

test_binar <- replicate(1000, {
  new.data <- simulate_Aliens_GLM()
  mod <- update(mod_binar, data = new.data)
  confint.myboot(mod)
  })

test_binom <- replicate(1000, {
  new.data <- simulate_Aliens_GLM()
  mod <- update(mod_binom, data = new.data)
  confint.myboot(mod)
  })

test_gauss <- replicate(1000, {
  new.data <- simulate_Aliens_GLM()
  mod <- update(mod_gauss, data = new.data)
  confint.myboot(mod)
  })
```


## 95% CI using parametric bootstrap

### Coverage N = 100
```{r}
rbind(poiss = apply(test_poiss, 1, mean),
      binar = apply(test_binar, 1, mean),
      binom = apply(test_binom, 1, mean),
      gauss = apply(test_gauss, 1, mean))
```

This is not good...


## 95% CI using parametric bootstrap

### A more serious approach of parametric bootstrap using ```boot```
```{r}
confint.myboot2 <- function(mod, print = FALSE) {
  new_betas <- replicate(100, {
    mod$data$newY <- simulate(mod, 1)[, 1]
    update(mod, newY ~ ., data = mod$data)$coef})
  
  intervals <- rbind(
    "(Intercept)" = boot::boot.ci(list(t0 = as.matrix(rep(coef(mod)[1][[1]], 100)),
                                       t = as.matrix(new_betas[1, ]), 
                                       R = 100), type = "basic")$basic[4:5],
    "humans_eaten" = boot::boot.ci(list(t0 = as.matrix(rep(coef(mod)[2][[1]], 100)),
                                        t = as.matrix(new_betas[2, ]),
                                        R = 100), type = "basic")$basic[4:5])
  if (print) print(intervals)
  name.response <- mod$terms[[2]]
  if (length(name.response) == 3) name.response <- name.response[[2]]  ## for  binomial with cbind
  true.intercept <- attributes(mod$data)$param.eta[[paste(name.response)]][1]
  true.slope <- attributes(mod$data)$param.eta[[paste(name.response)]][2]
  if (print) cat("\n true parameters in 95% CI? \n")
  c(true.intercept > intervals["(Intercept)", 1] & true.intercept < intervals["(Intercept)", 2],
    true.slope > intervals["humans_eaten", 1] & true.slope < intervals["humans_eaten", 2])
}
```


## 95% CI using parametric bootstrap

### Coverage N = 100
```{r  coverage boot2, message = FALSE, warning = FALSE}
set.seed(1L)
test_poiss <- replicate(1000, {
  new.data <- simulate_Aliens_GLM()
  mod <- update(mod_poiss, data = new.data)
  confint.myboot2(mod)
  })
test_binar <- replicate(1000, {
  new.data <- simulate_Aliens_GLM()
  mod <- update(mod_binar, data = new.data)
  confint.myboot2(mod)
  })
test_binom <- replicate(1000, {
  new.data <- simulate_Aliens_GLM()
  mod <- update(mod_binom, data = new.data)
  confint.myboot2(mod)
  })
test_gauss <- replicate(1000, {
  new.data <- simulate_Aliens_GLM()
  mod <- update(mod_gauss, data = new.data)
  confint.myboot2(mod)
  })
```


## 95% CI using parametric bootstrap

### Coverage N = 100
```{r}
rbind(poiss = apply(test_poiss, 1, mean),
      binar = apply(test_binar, 1, mean),
      binom = apply(test_binom, 1, mean),
      gauss = apply(test_gauss, 1, mean))
```

This is very good and our best result so far!


# Confidence intervals on the fitted values

## 95% CI on fitted values: Gaussian

### Using predict.lm from ```stats```
```{r}
mod_lm <- lm(size ~ humans_eaten, data = Aliens)
newdata <- data.frame(humans_eaten = c(5, 15))
predict(mod_lm, newdata = newdata, interval = "confidence")

pred <- predict(mod_gauss, newdata = newdata, se.fit = TRUE)
lwr <- pred$fit + qt(0.025, df = mod_lm$df.residual) * pred$se.fit
upr <- pred$fit + qt(0.975, df = mod_lm$df.residual) * pred$se.fit
pred.table <- cbind(fit = pred$fit, lwr, upr)
pred.table
```

## 95% CI on fitted values: Gaussian

### Using predict.glm from ```stats```
```{r}
pred <- predict(mod_gauss, newdata = newdata, se.fit = TRUE)
lwr <- pred$fit + qt(0.025, df = mod_lm$df.residual) * pred$se.fit
upr <- pred$fit + qt(0.975, df = mod_lm$df.residual) * pred$se.fit
pred.table <- cbind(fit = pred$fit, lwr, upr)
pred.table
```

Same with Gaussian approximation:
```{r}
pred <- predict(mod_gauss, newdata = newdata, se.fit = TRUE)
lwr <- pred$fit + qnorm(0.025) * pred$se.fit
upr <- pred$fit + qnorm(0.975) * pred$se.fit
pred.table <- cbind(fit = pred$fit, lwr, upr)
pred.table
```


## 95% CI on fitted values: Gaussian

### Using predict.HLfit from ```spaMM```

```{r, message = FALSE}
library(spaMM)
mod_gauss_spaMM <- fitme(size ~ humans_eaten, family = gaussian(), data = Aliens, method = "REML")
p <- predict(mod_gauss_spaMM, newdata = newdata, intervals = "predVar")
attr(p, "intervals")
get_intervals(mod_gauss_spaMM, newdata = newdata, intervals = "predVar")
```


## 95% CI on fitted values: Poisson

### On the scale of the linear predictor
```{r}
pred <- predict(mod_poiss, newdata = newdata, se.fit = TRUE)
lwr <- pred$fit + qnorm(0.025) * pred$se.fit
upr <- pred$fit + qnorm(0.975) * pred$se.fit
cbind(lwr, upr)

mod_poiss_spaMM <- fitme(eggs ~ humans_eaten, family = poisson(), data = Aliens, method = "REML")
log(get_intervals(mod_poiss_spaMM, newdata = newdata, intervals = "predVar"))  ## log to get eta!
```


## 95% CI on fitted values: Poisson

### On the scale of the response
```{r}
pred <- predict(mod_poiss, newdata = newdata, se.fit = TRUE)
lwr <- pred$fit + qnorm(0.025) * pred$se.fit
upr <- pred$fit + qnorm(0.975) * pred$se.fit
exp(cbind(lwr, upr))

get_intervals(mod_poiss_spaMM, newdata = newdata, intervals = "predVar")
```


## 95% CI on fitted values: Binomial

### Practice

Plot the predictions and confidence intervals for ```mod_binar``` and ```mod_binom``` for a number of humans eaten varying between 0 and 15.


## 95% CI on fitted values

### Conclusion

You have many options to get there, but if you do it manually never forget to first build the CI on the scale of the linear predictor and then transform all the values using the inverse link function.

### Never do the opposite!!!!! (SD should never be transformed)


# Prediction intervals

## 95% PI: Gaussian

```{r}
pred <- predict(mod_gauss, newdata = newdata, se.fit = TRUE)
lwr <- pred$fit + qt(0.025, df = mod_lm$df.residual) * sqrt(pred$se.fit^2 + pred$residual.scale^2)
upr <- pred$fit + qt(0.975, df = mod_lm$df.residual) * sqrt(pred$se.fit^2 + pred$residual.scale^2)
pred.table <- cbind(fit = pred$fit, lwr, upr)
pred.table
predict(mod_lm, newdata = newdata, interval = "prediction") ## uses t distribution
```

## 95% PI: Gaussian

```{r}
lwr <- pred$fit + qnorm(0.025) * sqrt(pred$se.fit^2 + pred$residual.scale^2)
upr <- pred$fit + qnorm(0.975) * sqrt(pred$se.fit^2 + pred$residual.scale^2)
cbind(lwr, upr)
get_intervals(mod_gauss_spaMM, newdata = newdata, intervals = "respVar")  ## uses gaussian approximation
```


## 95% PI: Poisson

### The residual variance is no longer constant!
```{r}
pred <- predict(mod_poiss, newdata = newdata, se.fit = TRUE)
lwr <- pred$fit + qnorm(0.025) * sqrt(pred$se.fit^2 + poisson()$variance(exp(pred$fit)))
upr <- pred$fit + qnorm(0.975) * sqrt(pred$se.fit^2 + poisson()$variance(exp(pred$fit)))
exp(cbind(lwr, upr))  ## don't forget the inverse link!
get_intervals(mod_poiss_spaMM, newdata = newdata, intervals = "respVar")  ## uses gaussian approximation
```


## 95% PI: Binomial

### Practice

Plot the predictions and prediction intervals for ```mod_binar``` and ```mod_binom``` for a number of humans eaten varying between 0 and 15.


# Summary tables

## New models

Let us refit models with less data to see differences in p-values more easily
```{r}
set.seed(1L)
Aliens2 <- simulate_Aliens_GLM(N = 20)
mod_lm2    <- lm(size  ~ humans_eaten, data = Aliens2)
mod_gauss2 <- glm(size  ~ humans_eaten, family = gaussian(), data = Aliens2)
mod_poiss2 <- glm(eggs  ~ humans_eaten, family = poisson(),  data = Aliens2)
mod_binar2 <- glm(happy ~ humans_eaten, family = binomial(), data = Aliens2)
mod_gauss2_spaMM  <- fitme(size  ~ humans_eaten, family = gaussian(), data = Aliens2) ## not REML!
mod_gauss2_spaMM0 <- fitme(size  ~ 1, family = gaussian(), data = Aliens2)
mod_poiss2_spaMM  <- fitme(eggs  ~ humans_eaten, family = poisson(),  data = Aliens2)
mod_poiss2_spaMM0 <- fitme(eggs  ~ 1, family = poisson(),  data = Aliens2)
mod_binar2_spaMM <- fitme(happy ~ humans_eaten, family = binomial(), data = Aliens2)
```


## Summary: Gaussian

```{r}
summary(mod_lm2)
```


## Summary: Gaussian

```{r}
summary(mod_gauss2)
```


## Summary: Gaussian

### Just like LM!
```{r}
summary(mod_gauss2)$coef
summary(mod_lm2)$coef
```

## Summary: Poisson

```{r}
summary(mod_poiss2)$coef
z <- (mod_poiss2$coef - 0) / sqrt(diag(vcov(mod_poiss2)))
pvalues <- 2 * (1 - pnorm(abs(z)))
cbind(z, pvalues)
```


## Summary: Binomial

```{r, cache = FALSE}
summary(mod_binar2)$coef
z <- (mod_binar2$coef - 0) / sqrt(diag(vcov(mod_binar2)))
pvalues <- 2 * (1 - pnorm(abs(z)))
cbind(z, pvalues)
```


# Anova

## Anova: Gaussian

### For gaussian() (and quasiXXX()) the F test is the one you should use!
```{r}
library(car)
Anova(mod_gauss2, test = "F")
```


## Anova: Gaussian

```{r}
Anova(mod_gauss2, test = "LR")
anova(mod_gauss2_spaMM, mod_gauss2_spaMM0)  ## "same" with spaMM
c(-2 * (logLik(update(mod_gauss2, . ~ 1)) - logLik(mod_gauss2)), 
  (deviance(update(mod_gauss2, . ~ 1)) - deviance(mod_gauss2)) / summary(mod_gauss2)$dispersion)
```

Note: the computation will differ between methods when dispersion is not equals to 1...


## Anova: Gaussian

```{r}
summary(mod_gauss2)$coef["humans_eaten", "t value"]
summary(mod_gauss2)$coef["humans_eaten", "t value"]^2
Anova(mod_gauss2, test = "F")
```


## $t^2$, $F$, and $\chi^2$

### Under certain conditions, these 3 distributions are the same:
* when $F_{df1 = 1}$ & when ```residuals.df``` $\rightarrow \infty$

```{r}
plot(ecdf(rt(10000, df = 5)^2), col = "blue", lwd = 3, main = "")
plot(ecdf(rf(10000, df1 = 1, df2 = 5)), add = TRUE, col = "red", lwd = 2)
plot(ecdf(rchisq(10000, df = 1)), add = TRUE, col = "green", lwd = 1)
```

## $t^2$, $F$, and $\chi^2$

### Under certain conditions, these 3 distributions are the same:
* when ```df1 = 1``` & when ```residuals.df``` $\rightarrow \infty$

```{r}
plot(ecdf(rt(10000, df = 500)^2), col = "blue", lwd = 3, main = "")
plot(ecdf(rf(10000, df1 = 1, df2 = 500)), add = TRUE, col = "red", lwd = 2)
plot(ecdf(rchisq(10000, df = 1)), add = TRUE, col = "green", lwd = 1)
```


## Anova: Poisson and Binomial

### For poisson() and binomial(), use the likelihood ratio test

### Don't use F test, don't use summary!!

```{r}
Anova(mod_poiss2, test = "LR")
LR <- -2 * (logLik(update(mod_poiss2, . ~ 1)) - logLik(mod_poiss2))
pvalue <- 1 - pchisq(LR, 1)
cbind(LR, pvalue)
```


## Anova: parametric bootstrap with ```spaMM```

### It works for all!
```{r lrt boot 1, message=FALSE}
anova(mod_gauss2_spaMM, mod_gauss2_spaMM0, boot.repl = 200)
```


## Anova: parametric bootstrap with ```spaMM```

### It works for all!
```{r lrt boot 2, message=FALSE}
anova(mod_poiss2_spaMM, mod_poiss2_spaMM0, boot.repl = 200)
```

# Non-nested model comparison

## Comparing different links or different families

Since the response variable does not change but models are not nested, you can use:

* likelihood (larger = better)
* deviance (smaller = better)
* AIC (smaller = better)

For true test, the only method available is the parametric bootstrap!


## Comparing LM vs GLM

### Responses differ, so only parametric bootstrap is possible
```{r}
set.seed(1L)
x <- seq(1, 2, length = 100)
y <- exp(rnorm(n = length(x), mean = 2 + 1 * x, sd = 0.5))

mod_lm   <- lm(log(y) ~ x)
mod_glm  <- glm(y ~ x, family = gaussian(link = "log"))
logLikH0 <- replicate(1000, {
  new.y <- exp(as.matrix(simulate(mod_lm)))
  logLik(lm(log(new.y) ~ x)) - logLik(glm(new.y ~ x, family = gaussian(link = "log")))
  })
mean(logLikH0 < (logLik(mod_lm) - logLik(mod_glm)))
```

Here we used the GLM as the null model so we simulate the data using the LM.

In principle, we could have do the opposite, but in practice the function ```simulate()``` bugs for GLM with gaussian(link != "identity").

## What you need to remember

* that estimates are still roughly normally distributed (but only roughly)
* how to compute intervals for GLM
* that intervals based on likelihood are best for family with known dispersion
* that established methods don't always work well, so you should always run tests
* that parametric bootstrap can outperform other methods when done properly
* that intervals on scale other than $\eta$ must be done by hand or using ```spaMM```
* that tests from summary tables are only reliable for the gaussian family
* that LR tests are best for family with known dispersion
* that LR tests by parametric bootstrap are best in all situations and easy to do with ```spaMM```


# Table of contents

## The Generalized Linear Model: GLM

* 3.0 [Introduction](./GLM_intro.html)
* 3.1 [Intervals & Tests](./GLM_intervals.html)
* 3.2 [Residuals & Assumptions](./GLM_assumptions.html)
* 3.3 [Let's practice more](./GLM_practice.html)

